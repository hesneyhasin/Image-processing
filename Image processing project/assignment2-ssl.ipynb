{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":8934830,"sourceId":14031007,"sourceType":"datasetVersion"}],"dockerImageVersionId":31193,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"papermill":{"default_parameters":{},"duration":2816.023032,"end_time":"2025-12-02T13:17:03.686719","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-02T12:30:07.663687","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics \"numpy<2\"\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\nimport cv2\nimport numpy as np\nimport seaborn as sns\n","metadata":{"execution":{"iopub.execute_input":"2025-12-07T10:19:57.903624Z","iopub.status.busy":"2025-12-07T10:19:57.902930Z","iopub.status.idle":"2025-12-07T10:20:00.264425Z","shell.execute_reply":"2025-12-07T10:20:00.263801Z","shell.execute_reply.started":"2025-12-07T10:19:57.903599Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Point to your segmentation data.yaml\nDATA_YAML_PATH = \"/kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/data.yaml\"  # change this\n\n# Where to save results\nOUTPUT_DIR = Path(\"/kaggle/working/yolov8s_seg_results\")\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(DATA_YAML_PATH)\nprint(OUTPUT_DIR)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-07T10:20:03.025207Z","iopub.status.busy":"2025-12-07T10:20:03.024516Z","iopub.status.idle":"2025-12-07T10:20:03.029710Z","shell.execute_reply":"2025-12-07T10:20:03.028868Z","shell.execute_reply.started":"2025-12-07T10:20:03.025184Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/data.yaml\n","/kaggle/working/yolov8s_seg_results\n"]}],"execution_count":2},{"cell_type":"code","source":"# Load COCO-pretrained YOLOv8s segmentation model\nmodel = YOLO(\"yolov8s-seg.pt\")\n\n# Train\nresults = model.train(\n    data=DATA_YAML_PATH,\n    epochs=50,\n    imgsz=640,\n    batch=8,\n    project=str(OUTPUT_DIR),\n    name=\"yolov8s-seg\",\n    exist_ok=True\n)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-07T10:20:07.161729Z","iopub.status.busy":"2025-12-07T10:20:07.161142Z","iopub.status.idle":"2025-12-07T11:39:31.609506Z","shell.execute_reply":"2025-12-07T11:39:31.608566Z","shell.execute_reply.started":"2025-12-07T10:20:07.161707Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.235 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s-seg, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/yolov8s_seg_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov8s_seg_results/yolov8s-seg, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients, 40.2 GFLOPs\n","\n","Transferred 411/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.4Â±11.7 MB/s, size: 28.4 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/train/labels... 3408 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3408/3408 463.1it/s 7.4s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/train is not writable, cache not saved.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±1.2 ms, read: 27.6Â±9.2 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 416.7it/s 2.3s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/yolov8s_seg_results/yolov8s-seg/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/yolov8s_seg_results/yolov8s-seg\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/50      2.37G       2.01      3.974      2.864      2.004         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.2it/s 1:22<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.4it/s 13.9s0.2s\n","                   all        974       1888     0.0953      0.108     0.0397     0.0123     0.0821     0.0794     0.0257    0.00596\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/50       2.9G      2.185      4.145      2.879      2.172         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.2it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.3it/s 14.1s0.2s\n","                   all        974       1888     0.0413     0.0694     0.0158     0.0039     0.0299     0.0381     0.0087    0.00193\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/50      2.94G      2.119      4.053      2.878      2.155         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.5it/s 13.6s0.2s\n","                   all        974       1888       0.14      0.158     0.0758     0.0256      0.117      0.128     0.0516     0.0134\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/50      2.98G      2.041      3.955      2.729       2.09         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.4it/s 13.8s0.2s\n","                   all        974       1888      0.208      0.172      0.101      0.037      0.173      0.137     0.0698     0.0189\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/50      3.02G      2.012      3.882      2.689      2.061         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.5it/s 13.6s0.2s\n","                   all        974       1888      0.222      0.186       0.11     0.0408      0.188       0.15     0.0776     0.0227\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/50      3.06G      1.929      3.762      2.558      1.971         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.3s0.2s\n","                   all        974       1888      0.267      0.229      0.155     0.0611      0.246      0.203      0.122     0.0378\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/50       3.1G      1.893      3.729       2.51      1.947         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.324      0.234      0.182     0.0707      0.294      0.201      0.137     0.0419\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/50      3.14G      1.872      3.613      2.428      1.908         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.5it/s 13.6s0.2s\n","                   all        974       1888      0.323      0.272      0.223     0.0929      0.315       0.23      0.183     0.0596\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/50      3.18G      1.836       3.57      2.364      1.871         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.382      0.285      0.249      0.101      0.346      0.245      0.195     0.0608\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/50      3.22G      1.819      3.544      2.323      1.854         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.3s0.2s\n","                   all        974       1888      0.355      0.273      0.238      0.103      0.331      0.252      0.196     0.0677\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/50      3.26G      1.789       3.47      2.265      1.836         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.4s0.2s\n","                   all        974       1888       0.45      0.326       0.32      0.142      0.401      0.294      0.268     0.0954\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/50       3.3G      1.762      3.422      2.223      1.819         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.4s0.2s\n","                   all        974       1888        0.4      0.339      0.306      0.133      0.371      0.301      0.259     0.0899\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/50      3.34G      1.735      3.369      2.191      1.799         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.2s0.2s\n","                   all        974       1888      0.382      0.352      0.293      0.128       0.37      0.315       0.26     0.0926\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/50      3.38G      1.727      3.344      2.137      1.796         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.2s0.2s\n","                   all        974       1888      0.476      0.374       0.37      0.174      0.443      0.352      0.329      0.124\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/50      3.42G      1.694      3.299      2.071       1.76         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 4.9it/s 1:28<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.1it/s 19.4s0.3ss\n","                   all        974       1888      0.441      0.375      0.363      0.177      0.438      0.328       0.32      0.125\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/50      3.46G      1.689      3.268      2.085      1.756         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.2it/s 1:22<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.3s0.2s\n","                   all        974       1888      0.449      0.398      0.375      0.177      0.427      0.365      0.341      0.127\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/50      3.51G      1.659       3.21      2.004      1.721         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.2s0.2s\n","                   all        974       1888      0.518      0.387      0.409      0.201      0.482      0.359      0.357      0.135\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/50      3.54G      1.645      3.171      1.975      1.717         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.524      0.397      0.415      0.204      0.512      0.369      0.383      0.153\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/50      3.58G      1.622      3.141       1.96      1.703         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.2s0.2s\n","                   all        974       1888      0.513      0.409      0.423      0.215      0.487      0.384      0.388      0.159\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/50      3.62G      1.616      3.137      1.899      1.693         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.1s0.2s\n","                   all        974       1888      0.494      0.421      0.433      0.218      0.453       0.38      0.374      0.147\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/50      3.66G      1.574      3.064      1.887      1.677         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.2s0.2s\n","                   all        974       1888      0.521      0.427       0.43      0.214      0.514      0.396      0.397      0.156\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/50      3.73G      1.567       3.03      1.832      1.656         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.557      0.448      0.481      0.249      0.536      0.422      0.439      0.176\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/50      3.79G      1.554      3.009      1.808      1.643         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 12.9s0.2s\n","                   all        974       1888      0.527      0.434      0.459      0.243      0.526      0.415       0.43      0.183\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/50      3.96G      1.545      3.003      1.781       1.63         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.6it/s 13.2s0.2s\n","                   all        974       1888      0.556      0.422      0.468       0.25      0.538      0.404      0.431      0.182\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/50      3.99G      1.522      2.938      1.731      1.615         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 12.9s0.2s\n","                   all        974       1888      0.615      0.467      0.521      0.284      0.593      0.445      0.487       0.21\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/50      4.03G      1.501      2.893       1.68        1.6         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.581      0.504      0.544      0.293      0.553      0.463      0.485      0.214\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/50      4.07G      1.493      2.894      1.675      1.596         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.1s0.2s\n","                   all        974       1888       0.58      0.462      0.501      0.276      0.563       0.44      0.465        0.2\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/50      4.16G      1.477      2.874      1.647      1.579         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.8s0.2s\n","                   all        974       1888      0.624      0.493      0.545      0.296      0.592       0.46        0.5      0.219\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/50       4.2G      1.462      2.828       1.62      1.572         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.599      0.508      0.549      0.309      0.591      0.474      0.508      0.226\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/50      4.28G      1.437      2.792      1.565      1.542         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.0s0.2s\n","                   all        974       1888      0.612      0.502      0.555      0.313      0.608      0.483      0.525      0.233\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/50      4.37G      1.423      2.749      1.552      1.534         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.8s0.2s\n","                   all        974       1888      0.662      0.508      0.583      0.341      0.652      0.487      0.553      0.255\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/50      4.41G      1.412       2.74      1.527      1.523         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.8s0.2s\n","                   all        974       1888      0.628      0.524      0.582      0.335      0.607      0.503      0.547      0.247\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/50      4.49G      1.398      2.716      1.507      1.513         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.8s0.2s\n","                   all        974       1888      0.703      0.492      0.584      0.339       0.69      0.481      0.561      0.253\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/50      4.56G       1.39      2.699      1.487      1.515         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.8s0.2s\n","                   all        974       1888      0.657      0.547       0.61      0.349       0.66      0.528      0.587      0.267\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/50      4.62G      1.387      2.693      1.457      1.509         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.6s0.2s\n","                   all        974       1888      0.649      0.576      0.613      0.356       0.65      0.553      0.596      0.272\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/50       4.7G      1.357      2.642      1.422      1.477         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.7s0.2s\n","                   all        974       1888      0.692      0.553      0.618      0.371      0.702      0.527      0.598      0.281\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/50      4.77G      1.355      2.647      1.415      1.482         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.6s0.2s\n","                   all        974       1888      0.652      0.576      0.628      0.378      0.648      0.549      0.604      0.287\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/50      4.83G      1.315      2.588       1.36      1.452         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.7s0.2s\n","                   all        974       1888      0.678      0.592      0.646      0.382      0.689       0.56      0.619       0.29\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/50      4.93G      1.315      2.571      1.338      1.445         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.7s0.2s\n","                   all        974       1888      0.691      0.589      0.658      0.399       0.68      0.575      0.632      0.307\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/50      4.97G      1.305      2.554      1.318      1.436         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.7s0.2s\n","                   all        974       1888      0.688      0.596      0.656      0.403      0.693      0.573      0.641      0.311\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/50      5.01G      1.281      2.451      1.215      1.485         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:21<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.6s0.2s\n","                   all        974       1888       0.73      0.609      0.679      0.421      0.713      0.594      0.659      0.321\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/50      5.07G      1.229      2.361      1.133      1.447         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.4s0.2s\n","                   all        974       1888      0.723      0.632      0.698      0.435      0.726      0.614      0.682      0.334\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/50      5.13G      1.192       2.31      1.064      1.415         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.8it/s 12.6s0.2s\n","                   all        974       1888      0.757      0.632      0.711      0.449      0.748      0.626       0.69      0.344\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/50      5.19G      1.167      2.263      1.039      1.396         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.5s0.2s\n","                   all        974       1888       0.74      0.648      0.717      0.455      0.756      0.619      0.701      0.351\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      45/50      5.27G      1.146      2.233      1.009      1.386         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.6s0.2s\n","                   all        974       1888      0.756      0.655      0.727      0.471      0.747      0.644      0.714      0.368\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      46/50      5.34G      1.121       2.21     0.9733      1.356         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.5s0.2s\n","                   all        974       1888      0.782      0.651      0.741      0.478      0.777       0.64      0.726      0.374\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      47/50      5.41G      1.101      2.178      0.946      1.342         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.5s0.2s\n","                   all        974       1888      0.776      0.664      0.741      0.479      0.772      0.659      0.734      0.376\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      48/50      5.49G      1.074      2.131      0.909       1.32         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.4s0.2s\n","                   all        974       1888      0.791      0.662      0.751      0.495      0.796      0.652      0.744      0.386\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      49/50      5.55G      1.055       2.11     0.8932      1.302         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.5s0.2s\n","                   all        974       1888      0.775      0.691      0.759      0.502      0.773      0.681      0.749      0.392\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      50/50      5.64G      1.045      2.098     0.8656      1.304         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 426/426 5.3it/s 1:20<0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.9it/s 12.4s0.2s\n","                   all        974       1888      0.796      0.671      0.758      0.505      0.792      0.666      0.752      0.396\n","\n","50 epochs completed in 1.310 hours.\n","Optimizer stripped from /kaggle/working/yolov8s_seg_results/yolov8s-seg/weights/last.pt, 23.9MB\n","Optimizer stripped from /kaggle/working/yolov8s_seg_results/yolov8s-seg/weights/best.pt, 23.9MB\n","\n","Validating /kaggle/working/yolov8s_seg_results/yolov8s-seg/weights/best.pt...\n","Ultralytics 8.3.235 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients, 39.9 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.7it/s 13.1s0.2s\n","                   all        974       1888      0.796      0.672      0.758      0.505      0.791      0.666       0.75      0.396\n","Speed: 0.2ms preprocess, 5.6ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/yolov8s_seg_results/yolov8s-seg\u001b[0m\n"]}],"execution_count":3},{"cell_type":"code","source":"best_model_path = OUTPUT_DIR / \"yolov8s-seg\" / \"weights\" / \"best.pt\"\nprint(best_model_path)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-07T11:48:32.283488Z","iopub.status.busy":"2025-12-07T11:48:32.282316Z","iopub.status.idle":"2025-12-07T11:48:32.288292Z","shell.execute_reply":"2025-12-07T11:48:32.287459Z","shell.execute_reply.started":"2025-12-07T11:48:32.283454Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/yolov8s_seg_results/yolov8s-seg/weights/best.pt\n"]}],"execution_count":4},{"cell_type":"code","source":"# Define image_files first\nval_dir = Path(DATA_YAML_PATH).parent / \"valid\" / \"images\"\nimage_files = list(val_dir.glob(\"*.jpg\"))[:6]\n\n# Now loop through them\nfor i, img_path in enumerate(image_files):\n    r = model.predict(str(img_path), conf=0.5)[0]\n    annotated = r.plot()\n    \n    # Save instead of show\n    save_path = OUTPUT_DIR / f\"inference_sample_{i}.jpg\"\n    cv2.imwrite(str(save_path), annotated)\n    print(f\"âœ“ Saved: {save_path}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-07T11:56:35.032219Z","iopub.status.busy":"2025-12-07T11:56:35.031881Z","iopub.status.idle":"2025-12-07T11:56:35.466261Z","shell.execute_reply":"2025-12-07T11:56:35.465626Z","shell.execute_reply.started":"2025-12-07T11:56:35.032196Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/images/akhand_b43_242_jpg.rf.c1acbe3699cfbc0f571819aa4ed3240a.jpg: 640x640 2 Car-Damages, 20.4ms\n","Speed: 3.2ms preprocess, 20.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n","âœ“ Saved: /kaggle/working/yolov8s_seg_results/inference_sample_0.jpg\n","\n","image 1/1 /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/images/severe_371_JPEG_jpg.rf.d383f95d374cb4559a99e86dce606f02.jpg: 640x640 1 Car-Damage, 20.4ms\n","Speed: 2.5ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","âœ“ Saved: /kaggle/working/yolov8s_seg_results/inference_sample_1.jpg\n","\n","image 1/1 /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/images/test_set_188_jpg.rf.518a3f6a609385e9706aba936e77e9e8.jpg: 640x640 2 Car-Damages, 20.3ms\n","Speed: 2.6ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","âœ“ Saved: /kaggle/working/yolov8s_seg_results/inference_sample_2.jpg\n","\n","image 1/1 /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/images/severe_87_JPEG_jpg.rf.944b8661e3dca47624d5d5d0b28ac335.jpg: 640x640 1 Car-Damage, 20.4ms\n","Speed: 2.5ms preprocess, 20.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","âœ“ Saved: /kaggle/working/yolov8s_seg_results/inference_sample_3.jpg\n","\n","image 1/1 /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/images/severe_55_JPEG_jpg.rf.3d704d7094ceadd6d1e7d359770821bb.jpg: 640x640 1 Car-Damage, 16.9ms\n","Speed: 2.5ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","âœ“ Saved: /kaggle/working/yolov8s_seg_results/inference_sample_4.jpg\n","\n","image 1/1 /kaggle/input/car-damage-detection1/Car-Damage detection.v1i.yolov8/valid/images/akhand_b43_31_jpg.rf.9a577ba464abda1fe10fa1e6dd5e2a90.jpg: 640x640 2 Car-Damages, 16.9ms\n","Speed: 2.6ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","âœ“ Saved: /kaggle/working/yolov8s_seg_results/inference_sample_5.jpg\n"]}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# CELL 1: INSTALL DEPENDENCIES\n# ============================================================\n!pip -q install ultralytics albumentations --no-deps\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-12-12T07:55:13.360469Z","iopub.status.busy":"2025-12-12T07:55:13.360155Z","iopub.status.idle":"2025-12-12T07:55:16.837804Z","shell.execute_reply":"2025-12-12T07:55:16.836902Z","shell.execute_reply.started":"2025-12-12T07:55:13.360445Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h"]}],"execution_count":1},{"cell_type":"code","source":"%%writefile /kaggle/working/data.yaml\ntrain: /kaggle/input/car-damage-detection/Car-Damage detection.v11.yolov8/train/images\nval: /kaggle/input/car-damage-detection/Car-Damage detection.v11.yolov8/valid/images\ntest: /kaggle/input/car-damage-detection/Car-Damage detection.v11.yolov8/test/images\n\nnc: 1\n\nnames: ['Car-Damage']\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T07:55:53.236431Z","iopub.status.busy":"2025-12-12T07:55:53.235848Z","iopub.status.idle":"2025-12-12T07:55:53.241546Z","shell.execute_reply":"2025-12-12T07:55:53.240935Z","shell.execute_reply.started":"2025-12-12T07:55:53.236405Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /kaggle/working/data.yaml\n"]}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# CELL 3: IMPORTS\n# ============================================================\nimport os\nimport glob\nimport random\nimport shutil\nimport yaml\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport gc\nimport torch\n\nfrom ultralytics import YOLO\nimport albumentations as A\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T07:55:56.058878Z","iopub.status.busy":"2025-12-12T07:55:56.058314Z","iopub.status.idle":"2025-12-12T07:55:57.548775Z","shell.execute_reply":"2025-12-12T07:55:57.548231Z","shell.execute_reply.started":"2025-12-12T07:55:56.058857Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"execution_count":4},{"cell_type":"code","source":"# ============================================================\n# CELL 4: IMPROVED SETTINGS\n# ============================================================\nBASE_DATASET = \"/kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8\"\nNUM_CLASSES = 1\nCLASS_NAMES = [\"Car-Damage\"]\nIMGSZ = 640\nDEVICE = 0  # Single GPU\nLABELED_FRACTION = 0.3  # INCREASED from 0.2\n\n# MixMatch-specific settings - IMPROVED\nMIXMATCH_WARMUP_EPOCHS = 60  # INCREASED from 40\nMIXMATCH_EPOCHS = 70  # INCREASED from 50\nBATCH_SIZE = 6\nMIXMATCH_CONF = 0.25  # DECREASED from 0.5\nK_AUGMENTATIONS = 4  # INCREASED from 2\nMIN_AREA = 500  # NEW: Minimum area filter for pseudo-labels\n\n# Paths\nMM_LABELED_PATH = \"/kaggle/working/mm_labeled\"\nMM_UNLABELED_PATH = \"/kaggle/working/mm_unlabeled\"\nMM_PSEUDO_PATH = \"/kaggle/working/mm_pseudo\"\nMM_MERGED_PATH = \"/kaggle/working/mm_merged\"\n\n# Create directories\nfor p in [MM_LABELED_PATH, MM_UNLABELED_PATH, MM_PSEUDO_PATH, MM_MERGED_PATH]:\n    os.makedirs(f\"{p}/images\", exist_ok=True)\n    os.makedirs(f\"{p}/labels\", exist_ok=True)\n\nprint(f\"âœ… Settings configured\")\nprint(f\"   Dataset: {BASE_DATASET}\")\nprint(f\"   Labeled fraction: {LABELED_FRACTION * 100}%\")\nprint(f\"   Warmup epochs: {MIXMATCH_WARMUP_EPOCHS}\")\nprint(f\"   SSL epochs: {MIXMATCH_EPOCHS}\")\nprint(f\"   Confidence threshold: {MIXMATCH_CONF}\")\nprint(f\"   K augmentations: {K_AUGMENTATIONS}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T07:56:01.092660Z","iopub.status.busy":"2025-12-12T07:56:01.092255Z","iopub.status.idle":"2025-12-12T07:56:01.100203Z","shell.execute_reply":"2025-12-12T07:56:01.099356Z","shell.execute_reply.started":"2025-12-12T07:56:01.092640Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Settings configured\n","   Dataset: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8\n","   Labeled fraction: 30.0%\n","   Warmup epochs: 60\n","   SSL epochs: 70\n","   Confidence threshold: 0.25\n","   K augmentations: 4\n"]}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# CELL 5: DATA SPLIT\n# ============================================================\ntrain_images_dir = f\"{BASE_DATASET}/train/images\"\ntrain_labels_dir = f\"{BASE_DATASET}/train/labels\"\n\nall_train_imgs = [\n    p for p in glob.glob(f\"{train_images_dir}/*.*\")\n    if p.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n]\n\nrandom.seed(42)\nrandom.shuffle(all_train_imgs)\n\nsplit_idx = int(len(all_train_imgs) * LABELED_FRACTION)\nlabeled_imgs = all_train_imgs[:split_idx]\nunlabeled_imgs = all_train_imgs[split_idx:]\n\nprint(f\"\\nðŸ“Š Data split:\")\nprint(f\"   Total: {len(all_train_imgs)} images\")\nprint(f\"   Labeled ({LABELED_FRACTION*100}%): {len(labeled_imgs)}\")\nprint(f\"   Unlabeled ({(1-LABELED_FRACTION)*100}%): {len(unlabeled_imgs)}\")\n\n# Copy labeled split\nfor img_path in tqdm(labeled_imgs, desc=\"Copying labeled\"):\n    base = os.path.basename(img_path)\n    lbl = base.replace(\".jpg\", \".txt\").replace(\".jpeg\", \".txt\").replace(\".png\", \".txt\")\n    shutil.copy(img_path, f\"{MM_LABELED_PATH}/images/{base}\")\n    lbl_path = f\"{train_labels_dir}/{lbl}\"\n    if os.path.exists(lbl_path):\n        shutil.copy(lbl_path, f\"{MM_LABELED_PATH}/labels/{lbl}\")\n\n# Copy unlabeled split\nfor img_path in tqdm(unlabeled_imgs, desc=\"Copying unlabeled\"):\n    base = os.path.basename(img_path)\n    lbl = base.replace(\".jpg\", \".txt\").replace(\".jpeg\", \".txt\").replace(\".png\", \".txt\")\n    shutil.copy(img_path, f\"{MM_UNLABELED_PATH}/images/{base}\")\n    lbl_path = f\"{train_labels_dir}/{lbl}\"\n    if os.path.exists(lbl_path):\n        shutil.copy(lbl_path, f\"{MM_UNLABELED_PATH}/labels/{lbl}\")\n\nprint(f\"âœ… Data split complete!\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T07:56:04.805608Z","iopub.status.busy":"2025-12-12T07:56:04.805324Z","iopub.status.idle":"2025-12-12T07:56:28.781402Z","shell.execute_reply":"2025-12-12T07:56:28.780681Z","shell.execute_reply.started":"2025-12-12T07:56:04.805580Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ðŸ“Š Data split:\n","   Total: 3408 images\n","   Labeled (30.0%): 1022\n","   Unlabeled (70.0%): 2386\n"]},{"name":"stderr","output_type":"stream","text":["Copying labeled: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1022/1022 [00:07<00:00, 137.10it/s]\n","Copying unlabeled: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2386/2386 [00:16<00:00, 145.37it/s]"]},{"name":"stdout","output_type":"stream","text":["âœ… Data split complete!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# CELL 6: IMPROVED AUGMENTATIONS\n# ============================================================\nweak_aug = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),  # NEW\n    A.RandomBrightnessContrast(p=0.3),\n    A.Rotate(limit=15, p=0.3),  # NEW\n])\n\nstrong_aug = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),  # NEW\n    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n    A.GaussNoise(p=0.3),\n    A.Blur(blur_limit=3, p=0.2),\n    A.Rotate(limit=20, p=0.4),  # NEW\n    A.ColorJitter(p=0.3),  # NEW\n])\n\ndef write_seg_label_file(out_txt, classes, masks_xy, img_shape):\n    h, w = img_shape\n    with open(out_txt, \"w\") as f:\n        for cls_id, poly in zip(classes, masks_xy):\n            if poly is None or len(poly) < 3:\n                continue\n            poly = np.array(poly, dtype=np.float32)\n            poly[:, 0] = np.clip(poly[:, 0] / w, 0.0, 1.0)\n            poly[:, 1] = np.clip(poly[:, 1] / h, 0.0, 1.0)\n            coords = \" \".join([f\"{v:.6f}\" for v in poly.reshape(-1)])\n            f.write(f\"{int(cls_id)} {coords}\\n\")\n\nprint(\"âœ… Augmentations defined\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T07:57:10.980349Z","iopub.status.busy":"2025-12-12T07:57:10.979784Z","iopub.status.idle":"2025-12-12T07:57:10.999695Z","shell.execute_reply":"2025-12-12T07:57:10.998595Z","shell.execute_reply.started":"2025-12-12T07:57:10.980309Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Augmentations defined\n"]}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# CELL 7: WARMUP PHASE\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸ”¥ MIXMATCH WARMUP PHASE\")\nprint(\"=\"*70)\n\nMM_DATA_YAML_LABELED = \"/kaggle/working/mm_labeled.yaml\"\nwith open(MM_DATA_YAML_LABELED, \"w\") as f:\n    yaml.safe_dump({\n        \"train\": f\"{MM_LABELED_PATH}/images\",\n        \"val\": f\"{BASE_DATASET}/valid/images\",\n        \"test\": f\"{BASE_DATASET}/test/images\",\n        \"nc\": NUM_CLASSES,\n        \"names\": CLASS_NAMES,\n    }, f, sort_keys=False)\n\nmm_base_model = YOLO(\"yolov8m-seg.pt\")\n\nprint(f\"\\nðŸš€ Starting warmup training ({MIXMATCH_WARMUP_EPOCHS} epochs)...\")\nmm_warmup_results = mm_base_model.train(\n    data=MM_DATA_YAML_LABELED,\n    epochs=MIXMATCH_WARMUP_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH_SIZE,\n    device=DEVICE,\n    project=\"/kaggle/working/mm_runs\",\n    name=\"mm_warmup\",\n    exist_ok=True,\n    patience=20,  # INCREASED from 10\n    amp=True,\n    verbose=False,\n    mosaic=0.9,\n    mixup=0.05,\n)\n\nmm_warmup_best = f\"{mm_warmup_results.save_dir}/weights/best.pt\"\nprint(f\"âœ… Warmup complete! Best: {mm_warmup_best}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T07:57:13.166204Z","iopub.status.busy":"2025-12-12T07:57:13.165617Z","iopub.status.idle":"2025-12-12T09:11:20.960944Z","shell.execute_reply":"2025-12-12T09:11:20.960133Z","shell.execute_reply.started":"2025-12-12T07:57:13.166167Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","ðŸ”¥ MIXMATCH WARMUP PHASE\n","======================================================================\n","\n","ðŸš€ Starting warmup training (60 epochs)...\n","Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mm_labeled.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.05, mode=train, model=yolov8m-seg.pt, momentum=0.937, mosaic=0.9, multi_scale=False, name=mm_warmup, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mm_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mm_runs/mm_warmup, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 16.7MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n","YOLOv8m-seg summary: 191 layers, 27,240,227 parameters, 27,240,211 gradients\n","\n","Transferred 531/537 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1178.1Â±439.2 MB/s, size: 38.2 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mm_labeled/labels.cache... 1022 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1022/1022 2.0Mit/s 0.0s0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 9.2Â±4.8 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 419.6it/s 2.3s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mm_runs/mm_warmup/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.000515625), 96 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mm_runs/mm_warmup\u001b[0m\n","Starting training for 60 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/60      3.21G      2.185      4.309      3.102       2.21         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.7s0.3ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888    0.00192      0.298    0.00127   0.000392   0.000633     0.0328   0.000327   8.13e-05\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/60      3.71G       2.51      4.669      3.343      2.533          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.4it/s 23.9s0.3ss\n","                   all        974       1888    0.00192    0.00742   0.000441   0.000118   0.000412     0.0122   0.000163   3.37e-05\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/60      3.79G      2.589      4.618      3.422      2.575         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 23.0s0.3ss\n","                   all        974       1888    0.00517      0.384    0.00795    0.00188    0.00663      0.103     0.0022   0.000383\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/60      3.86G      2.457       4.53      3.419      2.562          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.8s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.9s0.3ss\n","                   all        974       1888     0.0146      0.255     0.0147    0.00414    0.00875      0.153    0.00655    0.00145\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/60      3.94G      2.375      4.463      3.333      2.462          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.8s0.3ss\n","                   all        974       1888     0.0435      0.146     0.0243    0.00667     0.0294     0.0922     0.0142    0.00415\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/60         4G      2.355      4.429      3.263      2.448          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.5it/s 23.2s0.3ss\n","                   all        974       1888     0.0579      0.153     0.0221    0.00644     0.0338     0.0948    0.00993    0.00234\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/60      4.09G      2.256      4.427        3.2      2.336          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.6s0.3ss\n","                   all        974       1888     0.0909      0.098     0.0344     0.0104     0.0708     0.0689      0.023     0.0047\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/60      4.33G      2.214      4.377      3.175      2.323         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888     0.0844       0.13     0.0339     0.0104     0.0567      0.105     0.0168    0.00374\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/60       4.4G      2.167      4.288      3.055      2.262          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 23.1s0.3ss\n","                   all        974       1888     0.0836      0.176     0.0397     0.0136     0.0688      0.122     0.0222    0.00533\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/60      4.62G      2.186       4.33      3.066      2.269         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888      0.125      0.121     0.0522     0.0159      0.105     0.0805     0.0321    0.00774\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/60       4.7G      2.148      4.225      2.994      2.236          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.6s0.3ss\n","                   all        974       1888      0.122      0.146     0.0571     0.0185       0.11       0.11     0.0394    0.00954\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/60      4.91G      2.083      4.206      2.978      2.185          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.8s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888       0.17      0.164      0.075     0.0244       0.14      0.122     0.0462     0.0112\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/60      5.13G      2.082      4.121      2.955      2.175          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.153      0.141     0.0721      0.024      0.105      0.101     0.0407     0.0107\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/60      5.21G      2.042      4.086      2.873       2.14         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.6s0.3ss\n","                   all        974       1888      0.168      0.176     0.0859     0.0299      0.147      0.136     0.0627     0.0176\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/60      5.43G      2.051      4.072       2.86      2.136         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.5s0.3ss\n","                   all        974       1888      0.221       0.18     0.0976     0.0336      0.179      0.133     0.0627     0.0167\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/60       5.5G      2.041      4.074      2.874      2.118          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888      0.145      0.133     0.0689     0.0252       0.12      0.104     0.0467     0.0143\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/60      5.71G      2.003      4.015      2.774      2.071          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.5s0.3ss\n","                   all        974       1888      0.216      0.212      0.129     0.0457      0.178       0.16     0.0847     0.0241\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/60      5.79G      2.019      3.963      2.757      2.081          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.243      0.202       0.14     0.0504      0.236      0.169      0.105       0.03\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/60      6.04G      1.938      3.869      2.689      2.048          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.234      0.197      0.131     0.0487      0.213      0.167      0.097     0.0279\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/60      6.12G       1.98      3.973      2.721      2.065         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888      0.188      0.226      0.104     0.0377      0.181       0.18     0.0776     0.0208\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/60      6.34G       1.96      3.893      2.702      2.033          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.242      0.224      0.146     0.0524      0.225      0.181       0.11     0.0304\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/60      6.56G      1.922      3.839      2.642      2.022         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.276      0.225      0.155     0.0604      0.246      0.178      0.114     0.0338\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/60      6.64G      1.905      3.821      2.623      2.022         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.235      0.239      0.135     0.0523      0.222      0.201      0.101     0.0293\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/60      6.71G      1.903      3.792      2.557      2.008          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.264      0.253      0.165      0.064      0.248      0.215       0.13     0.0383\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/60      6.93G      1.922      3.846      2.629       2.03          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.241      0.213       0.13     0.0481      0.205      0.182     0.0885     0.0246\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/60      7.15G      1.881      3.774      2.541      1.988         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.292      0.262      0.177     0.0671      0.264      0.224      0.135     0.0395\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/60      7.23G      1.874      3.737      2.523      1.985          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.268      0.212      0.159     0.0601      0.221      0.179      0.111      0.033\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/60      7.44G      1.871      3.702       2.52      1.962          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.291      0.276      0.191     0.0769      0.268      0.228      0.148     0.0456\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/60      4.12G      1.846      3.666      2.496      1.962          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.297      0.305      0.201     0.0751      0.263      0.255       0.15     0.0438\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/60      4.12G      1.837      3.658      2.475      1.936          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.2s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.314      0.298      0.211     0.0844      0.296      0.239      0.163       0.05\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/60      4.12G      1.822      3.612      2.464      1.919         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.329      0.285      0.205     0.0847      0.305      0.233      0.165     0.0524\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/60      4.12G        1.8      3.623      2.409       1.91          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.323      0.296      0.222     0.0908      0.285      0.248      0.172     0.0563\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/60      4.17G      1.812      3.614      2.385      1.906          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.344      0.311      0.235     0.0939        0.3      0.256      0.177     0.0553\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/60      4.24G      1.793       3.57      2.349      1.898          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888       0.37      0.278      0.253      0.107       0.35      0.247      0.204     0.0672\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/60      4.32G      1.784      3.544      2.349      1.894         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.354      0.322      0.254      0.107      0.337       0.28        0.2     0.0639\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/60      4.39G      1.766      3.528      2.309      1.874         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888       0.37      0.309      0.262       0.11       0.35      0.263       0.21     0.0704\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/60      4.47G      1.761       3.49      2.276      1.862          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.405       0.32      0.283      0.121      0.373      0.271      0.223     0.0774\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/60       4.6G      1.777      3.508      2.275      1.882          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.417       0.33      0.286      0.124      0.388      0.288      0.235     0.0763\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/60      4.91G      1.742      3.451       2.29      1.866          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.378      0.329      0.275      0.122      0.369      0.282      0.237     0.0826\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/60         5G      1.735      3.458      2.283      1.865         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.379       0.33      0.271      0.116      0.348       0.28      0.219     0.0711\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/60      5.21G      1.691      3.453      2.223      1.816          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.384      0.342      0.293      0.129      0.391      0.279      0.242     0.0831\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/60      5.29G      1.717      3.417      2.206      1.837         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.9s0.3ss\n","                   all        974       1888      0.436      0.329      0.309      0.138       0.39      0.289      0.255     0.0889\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/60      5.64G      1.695      3.402      2.219      1.819          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.429      0.351       0.32      0.144      0.406      0.316      0.273     0.0956\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/60      5.71G      1.677      3.356      2.143      1.791          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.421      0.337      0.302      0.136      0.402      0.297      0.252     0.0882\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      45/60      5.79G      1.707      3.424      2.179      1.848         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.442      0.359      0.325      0.148       0.41      0.325      0.277     0.0992\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      46/60      6.05G      1.692      3.376        2.2      1.822         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.448      0.362      0.344      0.157      0.441      0.313      0.297      0.107\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      47/60      6.12G      1.686      3.381      2.111      1.812         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888       0.45      0.357      0.316      0.141      0.443      0.316      0.268     0.0921\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      48/60      6.34G      1.656      3.308      2.057      1.791         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.449      0.368      0.344      0.159      0.425      0.333      0.293      0.107\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      49/60      6.42G      1.633      3.254      2.091       1.77          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.437      0.371      0.336      0.152      0.434      0.326      0.284      0.104\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      50/60      6.63G      1.613      3.225      2.024      1.744         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.2s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.469      0.396      0.374      0.177      0.456      0.342      0.324      0.121\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      51/60      6.71G      1.603      3.145      2.005      1.811          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 50.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.473      0.367      0.362      0.173      0.455      0.335      0.316      0.118\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      52/60      6.93G      1.595      3.122      1.931       1.82          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.5it/s 49.5s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888       0.51      0.371      0.377      0.181      0.501      0.338      0.333      0.123\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      53/60      7.19G      1.579      3.039      1.873      1.799          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.6s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.469      0.387      0.367      0.177      0.452      0.358       0.32      0.119\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      54/60      7.26G      1.582       3.01      1.796      1.778          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.6s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.6s0.3ss\n","                   all        974       1888      0.508      0.398      0.403      0.194      0.493      0.365      0.355      0.136\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      55/60      7.34G      1.538      2.974      1.801      1.769          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.5it/s 49.5s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.6s0.3ss\n","                   all        974       1888      0.514      0.376       0.39      0.193      0.493      0.358      0.352      0.134\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      56/60      7.56G      1.541      2.948      1.773      1.765          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.4it/s 49.7s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.5s0.3ss\n","                   all        974       1888      0.515      0.403      0.404      0.199      0.535      0.365      0.362      0.138\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      57/60      5.08G      1.535       2.93      1.748      1.765          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.5it/s 49.4s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.5s0.3ss\n","                   all        974       1888      0.551      0.387      0.414      0.208      0.584      0.353      0.373      0.142\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      58/60      5.08G       1.49      2.908       1.73      1.718          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.5it/s 49.5s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.5s0.3ss\n","                   all        974       1888       0.57      0.396      0.422      0.211      0.538      0.365      0.376      0.142\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      59/60      5.08G      1.482      2.918      1.706      1.716          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.5it/s 49.5s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.6s0.3ss\n","                   all        974       1888      0.567      0.395      0.422      0.213      0.547      0.371      0.381      0.146\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      60/60      5.08G      1.457      2.858      1.668      1.695          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 3.5it/s 49.4s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.6s0.3ss\n","                   all        974       1888      0.575      0.399      0.425      0.214      0.556       0.37      0.381      0.147\n","\n","60 epochs completed in 1.222 hours.\n","Optimizer stripped from /kaggle/working/mm_runs/mm_warmup/weights/last.pt, 54.8MB\n","Optimizer stripped from /kaggle/working/mm_runs/mm_warmup/weights/best.pt, 54.8MB\n","\n","Validating /kaggle/working/mm_runs/mm_warmup/weights/best.pt...\n","Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8m-seg summary (fused): 105 layers, 27,222,963 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.9it/s 21.3s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.577      0.402      0.426      0.214      0.554      0.371      0.381      0.147\n","Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mm_runs/mm_warmup\u001b[0m\n","âœ… Warmup complete! Best: /kaggle/working/mm_runs/mm_warmup/weights/best.pt\n"]}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# CELL 8: IMPROVED PSEUDO-LABEL GENERATION\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸ·ï¸ MIXMATCH PSEUDO-LABELING\")\nprint(\"=\"*70)\n\nmm_model = YOLO(mm_warmup_best)\n\nunlabeled_imgs_mm = [\n    p for p in glob.glob(f\"{MM_UNLABELED_PATH}/images/*.*\")\n    if p.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n]\n\nprint(f\"ðŸ“ Pseudo-labeling {len(unlabeled_imgs_mm)} images...\")\nprint(f\"   Using {K_AUGMENTATIONS} augmentations, conf â‰¥ {MIXMATCH_CONF}\")\nprint(f\"   Min area filter: {MIN_AREA} pixels\")\n\npseudo_count = 0\nskipped_low_conf = 0\nskipped_small_area = 0\n\nfor img_path in tqdm(unlabeled_imgs_mm, desc=\"MixMatch pseudo-labels\"):\n    img = cv2.imread(img_path)\n    if img is None:\n        continue\n    \n    # Generate K augmented predictions\n    all_predictions = []\n    \n    for k in range(K_AUGMENTATIONS):\n        if k == 0:\n            aug = weak_aug(image=img)[\"image\"]\n        else:\n            aug = strong_aug(image=img)[\"image\"]\n        \n        results = mm_model.predict(\n            source=aug, \n            imgsz=IMGSZ, \n            conf=MIXMATCH_CONF,\n            save=False, \n            verbose=False\n        )\n        \n        if results and results[0].masks is not None:\n            all_predictions.append(results[0])\n    \n    if len(all_predictions) == 0:\n        skipped_low_conf += 1\n        continue\n    \n    # Use best prediction (highest average confidence)\n    best_pred = max(\n        all_predictions,\n        key=lambda r: r.boxes.conf.mean().item() if len(r.boxes) > 0 else 0\n    )\n    \n    if best_pred.masks is None or len(best_pred.boxes) == 0:\n        skipped_low_conf += 1\n        continue\n    \n    # Extract polygons with area filtering\n    classes = []\n    masks_xy = []\n    \n    for i in range(len(best_pred.boxes)):\n        if best_pred.boxes.conf[i] < MIXMATCH_CONF:\n            continue\n        \n        poly = best_pred.masks.xy[i]\n        \n        # Handle multiple contours\n        if isinstance(poly, list):\n            areas = [cv2.contourArea(np.array(p, dtype=np.float32)) for p in poly if len(p) >= 3]\n            if len(areas) == 0:\n                continue\n            poly = poly[int(np.argmax(areas))]\n        \n        if poly is None or len(poly) < 3:\n            continue\n        \n        # NEW: Area filter\n        area = cv2.contourArea(np.array(poly, dtype=np.float32))\n        if area < MIN_AREA:\n            skipped_small_area += 1\n            continue\n        \n        cls_id = int(best_pred.boxes.cls[i].item()) if hasattr(best_pred.boxes, \"cls\") else 0\n        classes.append(cls_id)\n        masks_xy.append(poly)\n    \n    if len(masks_xy) == 0:\n        continue\n    \n    # Apply strong augmentation for training image\n    strong = strong_aug(image=img)[\"image\"]\n    \n    # Save\n    base = os.path.splitext(os.path.basename(img_path))[0]\n    out_img = f\"{MM_PSEUDO_PATH}/images/{base}.jpg\"\n    out_lbl = f\"{MM_PSEUDO_PATH}/labels/{base}.txt\"\n    \n    write_seg_label_file(out_lbl, classes, masks_xy, strong.shape[:2])\n    cv2.imwrite(out_img, strong)\n    pseudo_count += 1\n\nprint(f\"âœ… Generated {pseudo_count} pseudo-labeled images\")\nprint(f\"   Skipped (low confidence): {skipped_low_conf}\")\nprint(f\"   Skipped (small area): {skipped_small_area}\")\nprint(f\"   Success rate: {pseudo_count / len(unlabeled_imgs_mm) * 100:.1f}%\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T09:17:04.694130Z","iopub.status.busy":"2025-12-12T09:17:04.693864Z","iopub.status.idle":"2025-12-12T09:23:07.889401Z","shell.execute_reply":"2025-12-12T09:23:07.888681Z","shell.execute_reply.started":"2025-12-12T09:17:04.694110Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","ðŸ·ï¸ MIXMATCH PSEUDO-LABELING\n","======================================================================\n","ðŸ“ Pseudo-labeling 2386 images...\n","   Using 4 augmentations, conf â‰¥ 0.25\n","   Min area filter: 500 pixels\n"]},{"name":"stderr","output_type":"stream","text":["MixMatch pseudo-labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2386/2386 [06:03<00:00,  6.57it/s]"]},{"name":"stdout","output_type":"stream","text":["âœ… Generated 2308 pseudo-labeled images\n","   Skipped (low confidence): 72\n","   Skipped (small area): 121\n","   Success rate: 96.7%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# CELL 9: MERGE & TRAIN\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸŽ“ MIXMATCH SSL TRAINING\")\nprint(\"=\"*70)\n\n# Merge datasets\ndef merge_dir_mm(src, dst):\n    for f in glob.glob(f\"{src}/*\"):\n        shutil.copy(f, f\"{dst}/{os.path.basename(f)}\")\n\nlabeled_count = len(os.listdir(f\"{MM_LABELED_PATH}/images\"))\npseudo_count = len(os.listdir(f\"{MM_PSEUDO_PATH}/images\"))\n\nprint(f\"\\nðŸ“Š MIXMATCH DATA SUMMARY\")\nprint(f\"   Labeled images ({LABELED_FRACTION*100}%): {labeled_count}\")\nprint(f\"   Pseudo-labeled (from {(1-LABELED_FRACTION)*100}%): {pseudo_count}\")\nprint(f\"   Total for training: {labeled_count + pseudo_count}\")\n\nmerge_dir_mm(f\"{MM_LABELED_PATH}/images\", f\"{MM_MERGED_PATH}/images\")\nmerge_dir_mm(f\"{MM_LABELED_PATH}/labels\", f\"{MM_MERGED_PATH}/labels\")\nmerge_dir_mm(f\"{MM_PSEUDO_PATH}/images\", f\"{MM_MERGED_PATH}/images\")\nmerge_dir_mm(f\"{MM_PSEUDO_PATH}/labels\", f\"{MM_MERGED_PATH}/labels\")\n\nmerged_count = len(os.listdir(f\"{MM_MERGED_PATH}/images\"))\nprint(f\"âœ… Merged: {merged_count} images\")\n\n# Create YAML\nMM_DATA_YAML_MERGED = \"/kaggle/working/mm_merged.yaml\"\nwith open(MM_DATA_YAML_MERGED, \"w\") as f:\n    yaml.safe_dump({\n        \"train\": f\"{MM_MERGED_PATH}/images\",\n        \"val\": f\"{BASE_DATASET}/valid/images\",\n        \"test\": f\"{BASE_DATASET}/test/images\",\n        \"nc\": NUM_CLASSES,\n        \"names\": CLASS_NAMES,\n    }, f, sort_keys=False)\n\n# Train with improved parameters\ngc.collect()\ntorch.cuda.empty_cache()\n\nmixmatch_model = YOLO(mm_warmup_best)\n\nprint(f\"\\nðŸš€ Starting MixMatch SSL training...\")\nprint(f\"   Epochs: {MIXMATCH_EPOCHS}\")\nprint(f\"   Batch: {BATCH_SIZE}\")\nprint(f\"   Patience: 20\")\n\nmm_results = mixmatch_model.train(\n    data=MM_DATA_YAML_MERGED,\n    epochs=MIXMATCH_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH_SIZE,\n    device=DEVICE,\n    project=\"/kaggle/working/mm_runs\",\n    name=\"mm_mixmatch\",\n    exist_ok=True,\n    patience=20,  # INCREASED from 10\n    amp=True,\n    verbose=False,\n    mosaic=0.7,  # INCREASED from 0.5\n    mixup=0.15,  # INCREASED from 0.1\n    conf=0.001,  # NEW: Lower inference threshold\n)\n\nmm_best = f\"{mm_results.save_dir}/weights/best.pt\"\nprint(f\"\\nâœ… MixMatch training complete!\")\nprint(f\"   Best model: {mm_best}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T09:25:38.642373Z","iopub.status.busy":"2025-12-12T09:25:38.641568Z","iopub.status.idle":"2025-12-12T13:07:29.225005Z","shell.execute_reply":"2025-12-12T13:07:29.223980Z","shell.execute_reply.started":"2025-12-12T09:25:38.642341Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","ðŸŽ“ MIXMATCH SSL TRAINING\n","======================================================================\n","\n","ðŸ“Š MIXMATCH DATA SUMMARY\n","   Labeled images (30.0%): 1022\n","   Pseudo-labeled (from 70.0%): 2366\n","   Total for training: 3388\n","âœ… Merged: 3388 images\n","\n","ðŸš€ Starting MixMatch SSL training...\n","   Epochs: 70\n","   Batch: 6\n","   Patience: 20\n","Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=0.001, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mm_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=70, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=/kaggle/working/mm_runs/mm_warmup/weights/best.pt, momentum=0.937, mosaic=0.7, multi_scale=False, name=mm_mixmatch, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mm_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mm_runs/mm_mixmatch, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n","YOLOv8m-seg summary: 191 layers, 27,240,227 parameters, 27,240,211 gradients\n","\n","Transferred 537/537 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1138.2Â±282.2 MB/s, size: 44.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mm_merged/labels... 3388 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3388/3388 945.1it/s 3.6s0.0s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mm_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±1.9 ms, read: 64.1Â±18.5 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 638.5it/s 1.5s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mm_runs/mm_mixmatch/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.000515625), 96 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mm_runs/mm_mixmatch\u001b[0m\n","Starting training for 70 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/70       3.8G      2.139      4.552      2.813      2.324         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.3it/s 2:52<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888       0.33      0.239      0.205     0.0815       0.28      0.194      0.146     0.0412\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/70      4.31G      2.203      4.608      2.983      2.359         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:48<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.5s0.3ss\n","                   all        974       1888      0.283      0.177      0.149     0.0541      0.252      0.142      0.101     0.0271\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/70      4.38G      2.251      4.639      3.049      2.407          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.8s0.3ss\n","                   all        974       1888       0.21       0.16     0.0895     0.0309      0.158      0.118     0.0474     0.0119\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/70      4.44G      2.266       4.64      3.053      2.418         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.6s0.3ss\n","                   all        974       1888      0.231      0.179      0.114     0.0416      0.178       0.15     0.0732     0.0204\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/70      4.53G       2.24      4.649      3.035      2.398         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.272      0.218      0.157     0.0581      0.247      0.176       0.12     0.0335\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/70      4.85G      2.191      4.623      2.976      2.361         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.279      0.211      0.163     0.0586      0.221       0.18      0.112     0.0319\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/70      4.92G      2.187      4.591      2.996      2.356         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.273      0.173       0.13     0.0479      0.245      0.145     0.0942     0.0265\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/70         5G      2.172      4.588      2.955      2.338         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.7s0.3ss\n","                   all        974       1888      0.311      0.177      0.155     0.0601      0.281      0.151       0.12      0.035\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/70      5.08G      2.166       4.59      2.943      2.346          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.286      0.235      0.168     0.0673      0.255      0.201      0.127     0.0376\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/70      5.33G      2.153       4.59      2.934      2.355         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.6s0.3ss\n","                   all        974       1888       0.29      0.233      0.176     0.0685      0.266      0.197      0.137     0.0416\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/70      5.41G      2.134      4.562      2.911      2.321         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.351      0.211      0.184     0.0721      0.303      0.182      0.143     0.0435\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/70      5.48G       2.14      4.562      2.897      2.318         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.328      0.249      0.218     0.0876      0.305      0.218      0.174     0.0549\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/70       5.7G      2.137      4.527      2.884      2.309         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.335      0.218      0.181      0.069      0.314      0.177      0.142     0.0439\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/70      5.92G       2.11      4.526       2.84      2.286         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.326      0.238      0.207     0.0785      0.295      0.205      0.155     0.0433\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/70      5.98G      2.092        4.5      2.835      2.273         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.359      0.258      0.216     0.0861      0.331      0.215      0.165      0.051\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/70      6.08G      2.082       4.49      2.806       2.26         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.341      0.256      0.199     0.0789      0.314      0.218      0.158     0.0484\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/70      6.29G      2.097      4.506      2.805      2.267         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.377      0.277       0.23     0.0911      0.339      0.223      0.175     0.0553\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/70      6.51G       2.08      4.495      2.793      2.265          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.345       0.27      0.215     0.0901      0.317       0.23      0.172     0.0522\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/70      6.58G       2.08      4.465      2.787      2.253         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.398      0.292      0.251     0.0999      0.357      0.262      0.204      0.067\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/70      6.81G      2.071      4.452      2.759      2.255          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.387      0.288      0.246     0.0954      0.357      0.253      0.205     0.0636\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/70      6.88G      2.073      4.487      2.786      2.252         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.3s0.3ss\n","                   all        974       1888      0.391      0.308      0.265      0.109      0.378      0.278      0.229     0.0742\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/70       7.1G      2.031      4.445      2.745      2.223          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.399       0.31      0.253      0.104      0.358      0.255      0.197     0.0646\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/70      7.32G      2.035       4.43      2.738       2.22          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.413      0.302      0.266      0.115      0.373      0.269      0.221     0.0729\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/70      7.39G      2.035      4.441      2.733      2.221         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.408      0.307      0.281      0.119      0.363      0.242       0.21     0.0689\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/70      5.55G      2.019      4.421        2.7      2.208         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.6it/s 22.5s0.3ss\n","                   all        974       1888      0.456      0.332       0.31      0.134      0.416      0.282      0.249     0.0838\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/70      5.55G      2.023      4.425      2.696      2.219         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888       0.45      0.321        0.3       0.13      0.424      0.283      0.248     0.0852\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/70      5.55G      2.006      4.418      2.682       2.21         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.445       0.31        0.3      0.132      0.435      0.275      0.255     0.0892\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/70      5.55G      2.016      4.404      2.706      2.205         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.4s0.3ss\n","                   all        974       1888      0.444      0.297      0.295      0.124        0.4      0.259      0.241     0.0805\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/70      5.57G      2.004      4.393      2.647      2.199          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.453      0.326      0.311      0.136      0.438      0.297      0.265     0.0885\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/70      5.64G      2.001      4.393      2.683      2.202         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.462      0.325      0.317      0.138       0.42      0.296       0.27     0.0914\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/70      5.72G      1.985      4.369      2.634      2.181         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.468      0.336      0.324      0.145      0.442      0.307       0.28     0.0998\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/70      5.79G      2.002      4.378      2.624      2.182         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.452      0.346      0.336      0.155      0.413      0.311      0.282      0.103\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/70      5.87G      1.976      4.352      2.602      2.172          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.461      0.364      0.334      0.146      0.413      0.309      0.268     0.0941\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/70      5.94G      1.962      4.364      2.592       2.16          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.487      0.353      0.346      0.156      0.463      0.307       0.29      0.102\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/70      6.01G      1.967      4.349      2.606       2.17         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.2s0.3ss\n","                   all        974       1888      0.505      0.354      0.343      0.157      0.461      0.309      0.287      0.103\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/70      6.09G       1.96      4.371      2.584      2.157         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.466      0.364      0.334      0.148      0.457      0.308      0.275     0.0957\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/70      6.15G      1.958      4.341      2.563      2.156         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.479      0.347      0.346      0.157      0.462      0.292      0.286      0.102\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/70      6.24G      1.943      4.327      2.557      2.135         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.515      0.347      0.353      0.168      0.492      0.317      0.304      0.115\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/70      6.31G      1.954      4.331      2.556      2.142         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.503      0.367      0.364       0.17      0.481      0.328      0.318      0.113\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/70      6.39G      1.967      4.343      2.577      2.145         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.493      0.358      0.359      0.167      0.449      0.321      0.305      0.116\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/70      6.71G      1.947      4.324       2.55      2.133          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.512      0.371      0.369      0.173       0.48      0.334      0.318      0.117\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/70      6.78G      1.936      4.313      2.547      2.134         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.477      0.373      0.363      0.169      0.458      0.333      0.315      0.115\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/70      6.85G      1.952      4.312      2.549       2.14         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.514      0.386      0.373      0.178      0.501      0.328      0.319      0.117\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/70      6.93G      1.924      4.329      2.535      2.125         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.525      0.373      0.378      0.177      0.509      0.331      0.322      0.113\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      45/70      7.25G      1.931      4.279      2.512      2.125         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.517      0.374       0.38      0.182      0.488      0.342      0.334      0.122\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      46/70      7.32G        1.9      4.264      2.475      2.104         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.516      0.378      0.372      0.179       0.51      0.335      0.327      0.125\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      47/70       7.4G      1.923      4.287        2.5      2.114          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.1s0.3ss\n","                   all        974       1888      0.562      0.391       0.41      0.196      0.524      0.353      0.358      0.132\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      48/70       5.6G      1.901      4.259      2.463      2.094         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.535        0.4      0.402       0.19      0.505      0.344      0.338      0.128\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      49/70       5.6G      1.892       4.29      2.463      2.083         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.539      0.389      0.402      0.193      0.517       0.36      0.352      0.131\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      50/70       5.6G      1.893      4.255      2.447       2.09          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.529      0.397      0.395      0.193      0.533      0.361      0.352      0.134\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      51/70       5.6G      1.889      4.258      2.448      2.086         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888       0.53      0.416      0.419      0.202      0.525      0.353      0.353      0.135\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      52/70      5.63G      1.897      4.279      2.466      2.105         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.549      0.407      0.416      0.201      0.518      0.369      0.355      0.132\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      53/70       5.7G      1.885      4.252      2.433      2.091         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.569      0.372      0.409      0.201      0.526      0.335      0.353      0.141\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      54/70      5.78G      1.867      4.253      2.426      2.071         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.552      0.418      0.427      0.215      0.556      0.359      0.367      0.142\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      55/70      5.85G      1.851      4.235      2.419      2.064         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.555      0.428      0.431      0.217      0.525      0.376      0.378      0.146\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      56/70      5.93G      1.843      4.219      2.378      2.063         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 21.9s0.3ss\n","                   all        974       1888      0.594      0.399      0.429       0.21      0.562      0.362      0.372      0.144\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      57/70         6G      1.845      4.217      2.387      2.067         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.9s0.3ss\n","                   all        974       1888      0.549      0.401      0.424      0.214      0.523      0.367      0.373      0.146\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      58/70      6.08G      1.852      4.207      2.398      2.067         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.7it/s 22.0s0.3ss\n","                   all        974       1888      0.521      0.415      0.421       0.21      0.503      0.374      0.362       0.14\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      59/70      6.14G      1.836      4.185      2.359      2.048          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.585      0.415      0.442      0.219      0.604      0.367      0.387      0.152\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      60/70      6.22G      1.833      4.187      2.344      2.045         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:47<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.589      0.427      0.448      0.225      0.536      0.396      0.394      0.158\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      61/70       6.3G      1.734      3.997      2.197      2.062          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.8s0.3ss\n","                   all        974       1888      0.588      0.418      0.442      0.226      0.539      0.382      0.381      0.153\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      62/70      6.38G      1.708      3.966      2.135      2.043          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:45<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.619      0.436      0.461      0.232        0.6      0.393      0.403       0.16\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      63/70      6.46G        1.7      3.953       2.11      2.032          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:45<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.627      0.421      0.452       0.23      0.575      0.376      0.383      0.153\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      64/70      6.53G      1.673       3.95      2.095      2.019         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:45<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.611      0.424      0.449      0.233      0.586      0.387      0.388      0.157\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      65/70      6.61G      1.681      3.935      2.093      2.012          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:45<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.631      0.431      0.457      0.238      0.591      0.384      0.398      0.161\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      66/70      6.68G      1.677      3.927      2.092      2.021         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.579      0.449      0.453      0.236      0.563      0.401        0.4      0.161\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      67/70      6.96G      1.665      3.908      2.055      2.002          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:45<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.629      0.434      0.463      0.242      0.606       0.39      0.401      0.163\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      68/70      7.03G      1.661      3.907      2.048      2.008         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.627      0.443      0.469      0.244      0.582      0.405      0.406      0.167\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      69/70      7.36G      1.652       3.89      2.036      1.999          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:46<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.623      0.444      0.468      0.245      0.607      0.402       0.41      0.166\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      70/70      7.42G      1.643      3.886      2.027      1.988          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 565/565 3.4it/s 2:45<0.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.7s0.3ss\n","                   all        974       1888      0.615      0.447      0.471      0.246      0.589        0.4      0.411      0.167\n","\n","70 epochs completed in 3.687 hours.\n","Optimizer stripped from /kaggle/working/mm_runs/mm_mixmatch/weights/last.pt, 54.8MB\n","Optimizer stripped from /kaggle/working/mm_runs/mm_mixmatch/weights/best.pt, 54.8MB\n","\n","Validating /kaggle/working/mm_runs/mm_mixmatch/weights/best.pt...\n","Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8m-seg summary (fused): 105 layers, 27,222,963 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 82/82 3.8it/s 21.4s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.616      0.444      0.471      0.246      0.588        0.4      0.411      0.167\n","Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mm_runs/mm_mixmatch\u001b[0m\n","\n","âœ… MixMatch training complete!\n","   Best model: /kaggle/working/mm_runs/mm_mixmatch/weights/best.pt\n"]}],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# CELL 10: VALIDATION\n# ============================================================\ndel mixmatch_model\ngc.collect()\ntorch.cuda.empty_cache()\n\nmm_final = YOLO(mm_best)\nmm_val_metrics = mm_final.val(split=\"test\", verbose=False)\n\nprint(f\"\\n{'='*70}\")\nprint(f\"MIXMATCH RESULTS\")\nprint(f\"{'='*70}\")\nprint(f\"   Mask mAP@0.5: {mm_val_metrics.seg.map50:.4f}\")\nprint(f\"   Mask mAP@0.5:0.95: {mm_val_metrics.seg.map:.4f}\")\nprint(f\"   Box mAP@0.5: {mm_val_metrics.box.map50:.4f}\")\nprint(f\"{'='*70}\")\nprint(f\"\\nâœ… MixMatch complete!\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-12T13:08:15.819775Z","iopub.status.busy":"2025-12-12T13:08:15.819057Z","iopub.status.idle":"2025-12-12T13:08:42.131856Z","shell.execute_reply":"2025-12-12T13:08:42.130876Z","shell.execute_reply.started":"2025-12-12T13:08:15.819740Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8m-seg summary (fused): 105 layers, 27,222,963 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 7.3Â±3.0 MB/s, size: 34.6 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/test/labels... 487 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 487/487 234.4it/s 2.1s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/test is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.6it/s 18.9s0.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        487        958      0.635      0.471      0.501      0.248      0.611      0.416       0.43      0.173\n","Speed: 1.5ms preprocess, 29.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val\u001b[0m\n","\n","======================================================================\n","MIXMATCH RESULTS\n","======================================================================\n","   Mask mAP@0.5: 0.4302\n","   Mask mAP@0.5:0.95: 0.1728\n","   Box mAP@0.5: 0.5007\n","======================================================================\n","\n","âœ… MixMatch complete!\n"]}],"execution_count":12},{"cell_type":"code","source":"!pip -q install ultralytics albumentations --no-deps","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:30:11.465300Z","iopub.status.busy":"2025-12-02T12:30:11.465036Z","iopub.status.idle":"2025-12-02T12:30:15.150748Z","shell.execute_reply":"2025-12-02T12:30:15.149804Z"},"papermill":{"duration":3.694118,"end_time":"2025-12-02T12:30:15.152415","exception":false,"start_time":"2025-12-02T12:30:11.458297","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h"]}],"execution_count":1},{"cell_type":"code","source":"%%writefile /kaggle/working/data.yaml\n# ============================================================\n# YOLOv12 Dataset Configuration for Instance Segmentation\n# ============================================================\n\ntrain: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/train/images\nval: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/images\ntest: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/test/images\n\n# Number of classes\nnc: 1\n\n# Class names\nnames: ['car-damage']","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:30:15.159267Z","iopub.status.busy":"2025-12-02T12:30:15.159025Z","iopub.status.idle":"2025-12-02T12:30:15.164882Z","shell.execute_reply":"2025-12-02T12:30:15.164250Z"},"papermill":{"duration":0.010393,"end_time":"2025-12-02T12:30:15.165870","exception":false,"start_time":"2025-12-02T12:30:15.155477","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/data.yaml\n"]}],"execution_count":2},{"cell_type":"code","source":"from ultralytics import YOLO\nimport albumentations as A\nimport os, glob, random, shutil, yaml, cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:30:15.172015Z","iopub.status.busy":"2025-12-02T12:30:15.171662Z","iopub.status.idle":"2025-12-02T12:30:21.171254Z","shell.execute_reply":"2025-12-02T12:30:21.170497Z"},"papermill":{"duration":6.004231,"end_time":"2025-12-02T12:30:21.172648","exception":false,"start_time":"2025-12-02T12:30:15.168417","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# 0) Paths & constants\n# ============================================================\nBASE_DATASET = \"/kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8\"   # dataset root (train/valid/test)\nDATA_YAML    = \"/kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/data.yamlD\"           # existing baseline yaml (optional)\n\nFM_LABELED_PATH   = \"/kaggle/working/fm_labeled\"\nFM_UNLABELED_PATH = \"/kaggle/working/fm_unlabeled\"\nFM_PSEUDO_PATH    = \"/kaggle/working/fm_pseudo\"      # strong-view pseudo-labeled images\nFM_MERGED_PATH    = \"/kaggle/working/fm_merged\"\n\nfor p in [FM_LABELED_PATH, FM_UNLABELED_PATH, FM_PSEUDO_PATH, FM_MERGED_PATH]:\n    os.makedirs(f\"{p}/images\", exist_ok=True)\n    os.makedirs(f\"{p}/labels\", exist_ok=True)\n\nNUM_CLASSES = 1\nCLASS_NAMES = [\"car-damage\"]\n\nLABELED_FRACTION = 0.2      # 20% labeled, 80% unlabeled\nWARMUP_EPOCHS    = 30       # supervised-only epochs\nFIXMATCH_EPOCHS  = 50       # training on labeled + pseudo-labeled\nIMGSZ            = 640\nBATCH            = 16\nDEVICE           = 0        # GPU id or \"cpu\"\nPSEUDO_CONF_TH   = 0.7      # FixMatch-style high confidence threshold\nMAX_PSEUDO       = None     # e.g. 500 to cap for speed","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:30:21.179321Z","iopub.status.busy":"2025-12-02T12:30:21.179002Z","iopub.status.idle":"2025-12-02T12:30:21.184711Z","shell.execute_reply":"2025-12-02T12:30:21.183955Z"},"papermill":{"duration":0.010315,"end_time":"2025-12-02T12:30:21.185902","exception":false,"start_time":"2025-12-02T12:30:21.175587","status":"completed"},"tags":[]},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================\n# 1) Weak & Strong augmentations (FixMatch style)\n#    Weak: minimal transform (reliable prediction)\n#    Strong: same geometry + heavier color/blur/noise\n# ============================================================\nweak_aug = A.Compose([\n    A.Resize(IMGSZ, IMGSZ),\n])\n\nstrong_aug = A.Compose([\n    A.Resize(IMGSZ, IMGSZ),\n    A.ColorJitter(p=0.5),\n    A.RandomBrightnessContrast(p=0.5),\n    A.GaussNoise(p=0.4),\n    A.MotionBlur(p=0.3),\n])","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:30:21.192205Z","iopub.status.busy":"2025-12-02T12:30:21.191697Z","iopub.status.idle":"2025-12-02T12:30:21.198761Z","shell.execute_reply":"2025-12-02T12:30:21.198013Z"},"papermill":{"duration":0.011322,"end_time":"2025-12-02T12:30:21.199863","exception":false,"start_time":"2025-12-02T12:30:21.188541","status":"completed"},"tags":[]},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# 2) Split dataset into labeled / unlabeled\n# ============================================================\nall_train_imgs = [\n    p for p in glob.glob(f\"{BASE_DATASET}/train/images/*.*\")\n    if p.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"))\n]\nrandom.shuffle(all_train_imgs)\n\nsplit_idx = int(len(all_train_imgs) * LABELED_FRACTION)\nlabeled_imgs   = all_train_imgs[:split_idx]\nunlabeled_imgs = all_train_imgs[split_idx:]\n\ndef safe_copy_pairs(image_paths, dst_root):\n    \"\"\"Copy images and their YOLO label .txt (if exists) to dst_root/images, dst_root/labels.\"\"\"\n    os.makedirs(f\"{dst_root}/images\", exist_ok=True)\n    os.makedirs(f\"{dst_root}/labels\", exist_ok=True)\n    for img in image_paths:\n        base = os.path.splitext(os.path.basename(img))[0]\n        lbl  = img.replace(\"/images/\", \"/labels/\").rsplit(\".\", 1)[0] + \".txt\"\n        shutil.copy(img, f\"{dst_root}/images/{os.path.basename(img)}\")\n        if os.path.exists(lbl):\n            shutil.copy(lbl, f\"{dst_root}/labels/{base}.txt\")\n\nsafe_copy_pairs(labeled_imgs,   FM_LABELED_PATH)\nsafe_copy_pairs(unlabeled_imgs, FM_UNLABELED_PATH)\n\nprint(f\"âœ… FixMatch split â†’ Labeled: {len(labeled_imgs)} | Unlabeled: {len(unlabeled_imgs)}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:30:21.206805Z","iopub.status.busy":"2025-12-02T12:30:21.206608Z","iopub.status.idle":"2025-12-02T12:31:25.931214Z","shell.execute_reply":"2025-12-02T12:31:25.930408Z"},"papermill":{"duration":64.731363,"end_time":"2025-12-02T12:31:25.934129","exception":false,"start_time":"2025-12-02T12:30:21.202766","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… FixMatch split â†’ Labeled: 681 | Unlabeled: 2727\n"]}],"execution_count":6},{"cell_type":"code","source":"# quick integrity check\nlab_img_names = {os.path.splitext(f)[0] for f in os.listdir(f\"{FM_LABELED_PATH}/images\")}\nlab_lbl_names = {os.path.splitext(f)[0] for f in os.listdir(f\"{FM_LABELED_PATH}/labels\")}\nprint(f\"ðŸ§© Integrity (labeled): images={len(lab_img_names)} labels={len(lab_lbl_names)}  missing_labels={len(lab_img_names - lab_lbl_names)}\")","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:31:25.940407Z","iopub.status.busy":"2025-12-02T12:31:25.940167Z","iopub.status.idle":"2025-12-02T12:31:25.946763Z","shell.execute_reply":"2025-12-02T12:31:25.946065Z"},"papermill":{"duration":0.010948,"end_time":"2025-12-02T12:31:25.947812","exception":false,"start_time":"2025-12-02T12:31:25.936864","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ§© Integrity (labeled): images=681 labels=681  missing_labels=0\n"]}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# 3) Build labeled YAML for warmup supervised training\n# ============================================================\nFM_DATA_YAML_LABELED = \"/kaggle/working/fm_labeled.yaml\"\nwith open(FM_DATA_YAML_LABELED, \"w\") as f:\n    yaml.safe_dump(\n        {\n            \"train\": f\"{FM_LABELED_PATH}/images\",\n            \"val\":   f\"{BASE_DATASET}/valid/images\",\n            \"test\":  f\"{BASE_DATASET}/test/images\",\n            \"nc\": NUM_CLASSES,\n            \"names\": CLASS_NAMES,\n        },\n        f,\n        sort_keys=False,\n    )\n\nprint(\"ðŸ”§ Labeled YAML:\\n\", open(FM_DATA_YAML_LABELED).read())","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:31:25.954095Z","iopub.status.busy":"2025-12-02T12:31:25.953720Z","iopub.status.idle":"2025-12-02T12:31:25.959286Z","shell.execute_reply":"2025-12-02T12:31:25.958681Z"},"papermill":{"duration":0.009795,"end_time":"2025-12-02T12:31:25.960333","exception":false,"start_time":"2025-12-02T12:31:25.950538","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ”§ Labeled YAML:\n"," train: /kaggle/working/fm_labeled/images\n","val: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/images\n","test: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/test/images\n","nc: 1\n","names:\n","- car-damage\n","\n"]}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# 4) Warmup: train base model on labeled subset\n# ============================================================\nbase_model = YOLO(\"yolov8s-seg.pt\")\nwarmup_results = base_model.train(\n    data=FM_DATA_YAML_LABELED,\n    epochs=WARMUP_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH,\n    device=0,\n    project=\"/kaggle/working/fm_runs\",\n    name=\"fm_warmup_teacher\",\n    exist_ok=True,\n    patience=10,\n    amp=True,\n)\nwarmup_best = f\"{warmup_results.save_dir}/weights/best.pt\"\nprint(\"âœ… Warmup best checkpoint:\", warmup_best)\n\n# Reload best warmup weights (FixMatch uses same network as \"teacher\" & \"student\")\nmodel = YOLO(warmup_best) \n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:31:25.967072Z","iopub.status.busy":"2025-12-02T12:31:25.966568Z","iopub.status.idle":"2025-12-02T12:46:40.704899Z","shell.execute_reply":"2025-12-02T12:46:40.703831Z"},"papermill":{"duration":914.743268,"end_time":"2025-12-02T12:46:40.706343","exception":false,"start_time":"2025-12-02T12:31:25.963075","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-seg.pt to 'yolov8s-seg.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 22.8MB 167.4MB/s 0.1s\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/fm_labeled.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fm_warmup_teacher, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/fm_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/fm_runs/fm_warmup_teacher, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 15.2MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 411/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 72.8MB/s 0.1s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 938.2Â±262.8 MB/s, size: 34.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/fm_labeled/labels... 681 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 681/681 1.1Kit/s 0.6s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/fm_labeled/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5.1Â±1.9 MB/s, size: 36.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 185.2it/s 5.3s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/fm_runs/fm_warmup_teacher/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/fm_runs/fm_warmup_teacher\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/30      4.16G      1.965      4.339      3.635      2.002         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.5it/s 17.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.6s\n","                   all        974       1888     0.0349     0.0312    0.00814    0.00251      0.021     0.0222    0.00264   0.000582\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/30      5.39G      2.175      4.118       2.94       2.15         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 3.0it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.6it/s 12.0s\n","                   all        974       1888    0.00546      0.018    0.00138   0.000509    0.00189    0.00424   0.000245   5.51e-05\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/30      5.43G      2.265      4.213      2.965      2.226         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 3.0it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.2it/s 14.0s\n","                   all        974       1888     0.0373     0.0281     0.0102     0.0024     0.0167     0.0323    0.00694    0.00103\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/30      5.47G      2.391      4.225      3.035      2.264         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.7it/s 11.3s\n","                   all        974       1888      0.019     0.0212    0.00705    0.00201    0.00587    0.00742    0.00244   0.000564\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/30      5.51G      2.283      4.199      2.896      2.164         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.8it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.6s\n","                   all        974       1888     0.0274     0.0609    0.00997    0.00277     0.0226     0.0249    0.00308   0.000671\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/30      5.55G      2.202      4.106      2.872      2.157         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.7s\n","                   all        974       1888     0.0804       0.12      0.032    0.00982      0.054     0.0736     0.0153    0.00396\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/30      5.59G      2.174      4.069      2.862      2.177         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.2it/s 13.9s\n","                   all        974       1888     0.0492      0.127     0.0208    0.00593     0.0293     0.0768    0.00765    0.00162\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/30      5.63G      2.115      4.056      2.761      2.112         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.7s\n","                   all        974       1888     0.0987      0.135     0.0442     0.0154     0.0913      0.106     0.0307    0.00864\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/30      5.67G      2.043      3.922      2.682      2.043         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.4s\n","                   all        974       1888      0.169      0.162     0.0829     0.0265      0.146       0.13     0.0552     0.0135\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/30      5.71G       2.04       3.98      2.682      2.042         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.6s\n","                   all        974       1888      0.167      0.199     0.0898     0.0322      0.148       0.16     0.0607     0.0166\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/30      5.75G      1.991       3.88      2.597      2.008         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.3s\n","                   all        974       1888      0.137      0.168      0.067     0.0238      0.125      0.151     0.0537     0.0156\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/30      5.79G       1.95      3.753      2.565      1.987         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.6s\n","                   all        974       1888      0.167      0.176     0.0853       0.03      0.155      0.142     0.0611     0.0157\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/30      5.83G      1.903      3.744       2.48      1.963         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.6s\n","                   all        974       1888      0.174      0.223      0.113     0.0399      0.184      0.181     0.0873     0.0247\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/30      5.87G      1.891      3.614       2.47      1.926         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.2s\n","                   all        974       1888      0.223      0.177      0.113     0.0427      0.217      0.155     0.0874     0.0246\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/30      5.91G      1.831      3.577      2.375      1.893         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.247      0.236      0.151      0.054      0.227       0.18      0.107     0.0308\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/30      5.95G      1.855      3.573      2.342      1.891         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.0s\n","                   all        974       1888      0.252      0.238      0.163     0.0626       0.23      0.199      0.123      0.037\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/30      5.99G      1.822      3.475        2.3      1.851         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.1s\n","                   all        974       1888      0.254      0.238      0.159     0.0626      0.242      0.207      0.133     0.0397\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/30      6.03G      1.802      3.528      2.282      1.836         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.5s\n","                   all        974       1888      0.223      0.281      0.147     0.0556      0.204      0.229      0.112     0.0333\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/30      6.07G      1.792       3.43      2.259      1.833         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.0s\n","                   all        974       1888      0.257      0.225      0.153     0.0626      0.241      0.197      0.119      0.035\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/30      6.11G      1.741      3.405      2.243      1.818         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888       0.34      0.267        0.2     0.0778      0.318      0.236      0.162     0.0466\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/30      6.16G      1.869      3.559      2.414      2.006         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.6it/s 16.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.3s\n","                   all        974       1888      0.279      0.255      0.176     0.0686      0.253      0.221      0.133     0.0399\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/30       6.2G      1.811      3.444      2.238      1.995         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.1s\n","                   all        974       1888      0.305      0.267      0.203     0.0741      0.258      0.219      0.147     0.0424\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/30      6.24G      1.779      3.332      2.139      1.935         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.7s\n","                   all        974       1888       0.32      0.303       0.24      0.102      0.296      0.264      0.197      0.063\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/30      6.28G      1.777      3.355      2.121      1.948         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.8s\n","                   all        974       1888      0.386      0.285       0.25      0.104      0.336      0.256      0.196      0.062\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/30      6.32G      1.699       3.22      2.012      1.886         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.7s\n","                   all        974       1888      0.358      0.318      0.264      0.111      0.338      0.263      0.209     0.0659\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/30      6.36G      1.719      3.186      1.952      1.897         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.8s\n","                   all        974       1888      0.395      0.332      0.284      0.127      0.371      0.294      0.236     0.0797\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/30       6.4G      1.658       3.09      1.911      1.851         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.413      0.318      0.298      0.128      0.345      0.282      0.236     0.0772\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/30      6.44G      1.602      3.002      1.838      1.814         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.424      0.352      0.329       0.15      0.385       0.32      0.278     0.0956\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/30      6.48G      1.563      2.966      1.787       1.78         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.446      0.356      0.344       0.16      0.425       0.32      0.295      0.106\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/30      6.52G      1.551      2.934      1.734      1.743         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 43/43 2.9it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.473      0.354      0.348      0.164      0.426      0.325      0.295      0.106\n","\n","30 epochs completed in 0.240 hours.\n","Optimizer stripped from /kaggle/working/fm_runs/fm_warmup_teacher/weights/last.pt, 23.9MB\n","Optimizer stripped from /kaggle/working/fm_runs/fm_warmup_teacher/weights/best.pt, 23.9MB\n","\n","Validating /kaggle/working/fm_runs/fm_warmup_teacher/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.473      0.354      0.349      0.164      0.429      0.324      0.295      0.106\n","Speed: 0.2ms preprocess, 6.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/fm_runs/fm_warmup_teacher\u001b[0m\n","âœ… Warmup best checkpoint: /kaggle/working/fm_runs/fm_warmup_teacher/weights/best.pt\n"]}],"execution_count":9},{"cell_type":"code","source":"\n# ============================================================\n# 5) FixMatch pseudo-labeling:\n#    weak(x_u) â†’ pseudo-label, strong(x_u) used for training\n# ============================================================\nto_label = unlabeled_imgs if MAX_PSEUDO is None else unlabeled_imgs[:MAX_PSEUDO]\nprint(f\"ðŸ“ FixMatch pseudo-labeling {len(to_label)} unlabeled images (conf â‰¥ {PSEUDO_CONF_TH})\")\n\ndef write_seg_label_file(out_txt, classes, masks_xy, img_shape):\n    \"\"\"\n    Write YOLO segmentation polygons to txt:\n    <cls> x1 y1 x2 y2 ... (normalized to [0,1]).\n    \"\"\"\n    h, w = img_shape  # (H, W)\n    with open(out_txt, \"w\") as f:\n        for cls_id, poly in zip(classes, masks_xy):\n            if poly is None or len(poly) < 3:\n                continue\n            poly = np.array(poly, dtype=np.float32)\n            poly[:, 0] = np.clip(poly[:, 0] / w, 0.0, 1.0)\n            poly[:, 1] = np.clip(poly[:, 1] / h, 0.0, 1.0)\n            coords = \" \".join([f\"{v:.6f}\" for v in poly.reshape(-1)])\n            f.write(f\"{int(cls_id)} {coords}\\n\")\n\nfor img_path in tqdm(to_label, desc=\"FixMatch pseudo-labels\"):\n    img = cv2.imread(img_path)\n    if img is None:\n        continue\n\n    # --- Weak view: used for prediction (pseudo-labels) ---\n    weak = weak_aug(image=img)[\"image\"]\n\n    # YOLO expects BGR uint8; weak is already resized\n    # Run prediction on weak view\n    results = model.predict(source=weak, imgsz=IMGSZ, conf=PSEUDO_CONF_TH, save=False, verbose=False)\n    if not results:\n        continue\n    r = results[0]\n    if r.masks is None or len(r.boxes) == 0:\n        continue\n\n    # Filter by confidence, like FixMatch's \"high confidence\" rule\n    confs = r.boxes.conf.cpu().numpy()\n    keep_idx = np.where(confs >= PSEUDO_CONF_TH)[0]\n    if keep_idx.size == 0:\n        continue\n\n    # Extract polygons & class ids for kept instances\n    classes = []\n    masks_xy = []\n    for i in keep_idx:\n        if r.masks is None or r.masks.xy is None:\n            continue\n        polys = r.masks.xy[i]\n        if isinstance(polys, list):\n            # choose largest polygon by area\n            areas = [cv2.contourArea(np.array(p, dtype=np.float32)) for p in polys if len(p) >= 3]\n            if len(areas) == 0:\n                continue\n            poly = polys[int(np.argmax(areas))]\n        else:\n            poly = polys\n        if poly is None or len(poly) < 3:\n            continue\n        cls_id = int(r.boxes.cls[i].item()) if hasattr(r.boxes, \"cls\") else 0\n        classes.append(cls_id)\n        masks_xy.append(poly)\n\n    if len(masks_xy) == 0:\n        continue\n\n    # --- Strong view: used for actual training image in FixMatch ---\n    strong = strong_aug(image=img)[\"image\"]\n\n    # Save strong-view image + label with pseudo-labels from weak view\n    base = os.path.splitext(os.path.basename(img_path))[0]\n    out_img = f\"{FM_PSEUDO_PATH}/images/{base}.jpg\"\n    out_lbl = f\"{FM_PSEUDO_PATH}/labels/{base}.txt\"\n\n    # Ensure shape is IMGSZ x IMGSZ\n    h, w = strong.shape[:2]\n    assert h == IMGSZ and w == IMGSZ, \"Strong view must be resized to IMGSZ\"\n\n    write_seg_label_file(out_lbl, classes, masks_xy, (h, w))\n    cv2.imwrite(out_img, strong)\n\nprint(\"âœ… FixMatch pseudo-label generation complete.\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:46:40.935817Z","iopub.status.busy":"2025-12-02T12:46:40.935263Z","iopub.status.idle":"2025-12-02T12:47:32.466762Z","shell.execute_reply":"2025-12-02T12:47:32.465821Z"},"papermill":{"duration":51.638602,"end_time":"2025-12-02T12:47:32.468025","exception":false,"start_time":"2025-12-02T12:46:40.829423","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ“ FixMatch pseudo-labeling 2727 unlabeled images (conf â‰¥ 0.7)\n"]},{"name":"stderr","output_type":"stream","text":["FixMatch pseudo-labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2727/2727 [00:51<00:00, 52.94it/s]"]},{"name":"stdout","output_type":"stream","text":["âœ… FixMatch pseudo-label generation complete.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# 6) Merge labeled data + FixMatch pseudo-labeled strong views\n# ============================================================\ndef merge_dir(src, dst):\n    for f in glob.glob(f\"{src}/*\"):\n        shutil.copy(f, f\"{dst}/{os.path.basename(f)}\")\n\nmerge_dir(f\"{FM_LABELED_PATH}/images\", f\"{FM_MERGED_PATH}/images\")\nmerge_dir(f\"{FM_LABELED_PATH}/labels\", f\"{FM_MERGED_PATH}/labels\")\nmerge_dir(f\"{FM_PSEUDO_PATH}/images\",  f\"{FM_MERGED_PATH}/images\")\nmerge_dir(f\"{FM_PSEUDO_PATH}/labels\",  f\"{FM_MERGED_PATH}/labels\")\n\nFM_DATA_YAML_MERGED = \"/kaggle/working/fm_merged.yaml\"\nwith open(FM_DATA_YAML_MERGED, \"w\") as f:\n    yaml.safe_dump(\n        {\n            \"train\": f\"{FM_MERGED_PATH}/images\",\n            \"val\":   f\"{BASE_DATASET}/valid/images\",\n            \"test\":  f\"{BASE_DATASET}/test/images\",\n            \"nc\": NUM_CLASSES,\n            \"names\": CLASS_NAMES,\n        },\n        f,\n        sort_keys=False,\n    )\n\nprint(\"ðŸ”§ Merged YAML:\\n\", open(FM_DATA_YAML_MERGED).read())","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:47:32.714059Z","iopub.status.busy":"2025-12-02T12:47:32.713620Z","iopub.status.idle":"2025-12-02T12:47:32.922471Z","shell.execute_reply":"2025-12-02T12:47:32.921768Z"},"papermill":{"duration":0.331752,"end_time":"2025-12-02T12:47:32.923604","exception":false,"start_time":"2025-12-02T12:47:32.591852","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ”§ Merged YAML:\n"," train: /kaggle/working/fm_merged/images\n","val: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/images\n","test: /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/test/images\n","nc: 1\n","names:\n","- car-damage\n","\n"]}],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# 7) Train model on merged dataset (labeled + FixMatch pseudo)\n# ============================================================\nfixmatch_model = YOLO(warmup_best)\nfm_results = fixmatch_model.train(\n    data=FM_DATA_YAML_MERGED,\n    epochs=FIXMATCH_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH,\n    device=0,\n    project=\"/kaggle/working/fm_runs\",\n    name=\"fm_fixmatch_student\",\n    exist_ok=True,\n    patience=10,\n    amp=True,\n)\nfm_best = f\"{fm_results.save_dir}/weights/best.pt\"\nprint(\"âœ… FixMatch student best checkpoint:\", fm_best)\n\n# (Optional) Validate\n_ = fixmatch_model.val(split=\"val\")","metadata":{"execution":{"iopub.execute_input":"2025-12-02T12:47:33.169836Z","iopub.status.busy":"2025-12-02T12:47:33.169591Z","iopub.status.idle":"2025-12-02T13:16:58.456230Z","shell.execute_reply":"2025-12-02T13:16:58.455230Z"},"papermill":{"duration":1765.410699,"end_time":"2025-12-02T13:16:58.458255","exception":false,"start_time":"2025-12-02T12:47:33.047556","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/fm_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/fm_runs/fm_warmup_teacher/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fm_fixmatch_student, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/fm_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/fm_runs/fm_fixmatch_student, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1684.8Â±1292.2 MB/s, size: 167.1 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/fm_merged/labels... 945 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 945/945 1.2Kit/s 0.8s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/fm_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.2 ms, read: 21.4Â±17.8 MB/s, size: 30.6 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 433.8it/s 2.2s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/fm_runs/fm_fixmatch_student/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/fm_runs/fm_fixmatch_student\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/50      4.68G      1.646      3.138      2.039      1.752          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.6it/s 22.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.2s\n","                   all        974       1888       0.32      0.238      0.184     0.0729      0.289      0.219      0.155     0.0456\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/50      5.87G        1.7      3.149      2.082      1.759          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.8it/s 21.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.253      0.219      0.154     0.0578      0.207       0.16      0.097     0.0262\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/50      5.87G      1.818      3.454      2.269      1.872          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.2it/s 13.8s\n","                   all        974       1888      0.208      0.218      0.124     0.0423        0.2      0.158     0.0919      0.024\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/50      5.88G      1.863      3.459       2.28      1.851          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.283      0.236      0.183     0.0703      0.236       0.21      0.135     0.0405\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/50      5.92G      1.808      3.491      2.256      1.847          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.2s\n","                   all        974       1888      0.261        0.2      0.159     0.0572      0.254      0.135     0.0984     0.0259\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/50      5.96G      1.816      3.392      2.256      1.864          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.3s\n","                   all        974       1888      0.288      0.217      0.173     0.0634      0.271       0.18      0.134     0.0364\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/50         6G      1.804      3.404      2.167      1.855          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.282      0.231      0.175     0.0669      0.256      0.199      0.128     0.0382\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/50      6.04G       1.78      3.322      2.183      1.859          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.3s\n","                   all        974       1888      0.292      0.261      0.202      0.077      0.289      0.236      0.173     0.0523\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/50      6.08G      1.753      3.311       2.11      1.785          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.0s\n","                   all        974       1888      0.296      0.246      0.167     0.0598      0.238      0.182      0.105     0.0283\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/50      6.12G       1.73       3.26      2.095      1.782          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.357      0.229      0.202     0.0755      0.306      0.185      0.147     0.0421\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/50      6.16G      1.713       3.24      2.042      1.795          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.336      0.288      0.234     0.0919      0.308      0.248      0.184      0.057\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/50       6.2G      1.708      3.205      2.068      1.801          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.295      0.235      0.173     0.0667      0.273      0.209      0.141     0.0438\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/50      6.23G      1.694      3.226      2.056      1.767          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.8s\n","                   all        974       1888      0.372      0.264      0.235     0.0903      0.349      0.227      0.188     0.0571\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/50      6.28G      1.642      3.113      2.017      1.735          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.0s\n","                   all        974       1888      0.357      0.275       0.23     0.0953      0.326      0.256      0.188      0.063\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/50      6.31G      1.607      3.069      1.881      1.675          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.7s\n","                   all        974       1888      0.315       0.28      0.215     0.0882      0.309      0.245      0.183     0.0604\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/50      6.36G      1.623      3.052      1.905      1.733          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.364      0.292      0.247      0.107      0.362       0.26      0.213     0.0697\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/50      6.39G      1.636      3.101       1.93      1.733          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.0s\n","                   all        974       1888      0.352      0.286       0.23     0.0995      0.351      0.234      0.193     0.0626\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/50      6.43G      1.619      3.026      1.843      1.695          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.8s\n","                   all        974       1888      0.298      0.315      0.226     0.0946      0.315      0.265      0.193      0.064\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/50      6.47G      1.561      2.997      1.803      1.654          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.9s\n","                   all        974       1888      0.383      0.322      0.275      0.115       0.33      0.285      0.212     0.0705\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/50      6.51G       1.56      2.959      1.768      1.651          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.2s\n","                   all        974       1888      0.366      0.268      0.242      0.101      0.311      0.245      0.197     0.0642\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/50      6.56G      1.597      2.953      1.809      1.682          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.343      0.303      0.236     0.0962       0.31      0.262      0.187     0.0592\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/50      6.59G      1.548      2.965      1.725      1.631          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.416      0.326      0.288      0.123      0.386      0.299      0.246     0.0803\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/50      6.63G      1.508      2.868      1.653      1.612          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.4s\n","                   all        974       1888      0.439      0.335      0.327      0.141      0.421      0.308      0.289      0.101\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/50      6.67G      1.501       2.87      1.663      1.592          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.413       0.37      0.333      0.145      0.406      0.326      0.288      0.101\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/50      6.71G      1.517      2.859      1.606      1.633          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.458      0.343      0.333      0.145      0.424        0.3      0.276     0.0917\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/50      6.75G      1.489      2.858       1.61      1.576          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.443      0.362      0.333      0.145      0.423      0.336      0.293      0.103\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/50      6.79G      1.439      2.807      1.582      1.565          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.8s\n","                   all        974       1888       0.45      0.346      0.327      0.149      0.449      0.317      0.289      0.104\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/50      6.83G      1.443      2.718       1.56      1.564          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 12.8s\n","                   all        974       1888      0.413      0.357      0.305      0.142       0.42      0.308      0.263     0.0966\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/50      6.87G      1.428      2.746      1.543      1.551          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.484      0.374      0.352       0.16      0.455      0.342      0.309      0.112\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/50      6.91G      1.399      2.712      1.477      1.522          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.7s\n","                   all        974       1888      0.472      0.393      0.365      0.166      0.442      0.355      0.313      0.116\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/50      6.95G      1.383      2.713      1.443      1.516          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.484      0.355      0.358      0.167      0.436      0.317      0.296       0.11\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/50      6.99G      1.441      2.746      1.513      1.546         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.3s\n","                   all        974       1888      0.492      0.363      0.365      0.169      0.444      0.325      0.311      0.116\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/50      7.03G      1.374      2.648      1.418        1.5          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.4s\n","                   all        974       1888      0.495      0.378      0.376      0.179      0.453      0.354      0.338      0.129\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/50      7.07G      1.361      2.639      1.395        1.5          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.457      0.387      0.339      0.158      0.433       0.35        0.3      0.113\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/50      7.11G      1.358      2.635      1.422      1.487          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.4s\n","                   all        974       1888      0.517       0.39      0.396       0.19      0.495      0.352      0.339      0.131\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/50      7.16G      1.346      2.615      1.345      1.494          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.4s\n","                   all        974       1888      0.495      0.394      0.381      0.181      0.487      0.363      0.346      0.128\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/50      7.19G      1.321      2.532      1.335      1.476          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.516      0.385      0.381      0.184      0.484       0.36      0.332      0.129\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/50      7.23G       1.32      2.559      1.355      1.472          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.497      0.386      0.386      0.188      0.475      0.359      0.341      0.135\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/50      7.27G      1.293       2.52      1.249      1.432          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.516      0.404      0.405      0.196      0.498      0.359      0.347      0.138\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/50      7.31G      1.294      2.484      1.249       1.44          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 21.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.512      0.392      0.399      0.196      0.471       0.36      0.348      0.135\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/50      7.35G      1.271      2.411      1.282      1.466          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.7it/s 22.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.5s\n","                   all        974       1888      0.526      0.406      0.406      0.202      0.515      0.361      0.359       0.14\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/50       7.4G      1.212      2.341      1.139      1.475          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.4s\n","                   all        974       1888      0.541      0.403      0.414      0.202      0.508      0.372      0.358      0.141\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/50      4.91G      1.174      2.245      1.102      1.424          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.3s\n","                   all        974       1888      0.538      0.427      0.432      0.212      0.538       0.38      0.385      0.153\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/50      4.91G      1.158      2.272      1.069      1.404          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.2s\n","                   all        974       1888      0.531      0.425      0.427      0.211      0.512      0.405      0.383       0.15\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      45/50      4.91G      1.126      2.205      1.018      1.373          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.3s\n","                   all        974       1888      0.543      0.432      0.434      0.219      0.549      0.387      0.382      0.155\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      46/50      4.91G      1.096      2.136     0.9885      1.361          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.3s\n","                   all        974       1888      0.585      0.427      0.449      0.228      0.557      0.395      0.398      0.164\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      47/50      4.95G      1.071      2.098     0.9521      1.357          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.2s\n","                   all        974       1888      0.583       0.43      0.442      0.223      0.561      0.393      0.389      0.157\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      48/50      4.98G      1.039      2.051     0.8802      1.314          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.607      0.434      0.461      0.234      0.593      0.394       0.41      0.169\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      49/50      5.01G      1.077      2.168     0.9768      1.347          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.6s\n","                   all        974       1888      0.583      0.431      0.456      0.234      0.607      0.391      0.412      0.168\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      50/50      5.04G      1.012      1.998     0.8583      1.298          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 2.9it/s 20.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.5it/s 12.4s\n","                   all        974       1888      0.633      0.421      0.462      0.238      0.615      0.391      0.413      0.171\n","\n","50 epochs completed in 0.476 hours.\n","Optimizer stripped from /kaggle/working/fm_runs/fm_fixmatch_student/weights/last.pt, 23.9MB\n","Optimizer stripped from /kaggle/working/fm_runs/fm_fixmatch_student/weights/best.pt, 23.9MB\n","\n","Validating /kaggle/working/fm_runs/fm_fixmatch_student/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.3it/s 13.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.633      0.421      0.462      0.238      0.615       0.39      0.413      0.171\n","Speed: 0.2ms preprocess, 6.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/fm_runs/fm_fixmatch_student\u001b[0m\n","âœ… FixMatch student best checkpoint: /kaggle/working/fm_runs/fm_fixmatch_student/weights/best.pt\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 36.1Â±20.5 MB/s, size: 35.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 689.8it/s 1.4s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.1it/s 19.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.637      0.421      0.462      0.237      0.615       0.39      0.413      0.171\n","Speed: 1.1ms preprocess, 12.8ms inference, 0.0ms loss, 1.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val\u001b[0m\n"]}],"execution_count":12},{"cell_type":"code","source":"# ============================================================\n# FIND BEST.PT FILES\n# ============================================================\nimport os\nimport glob\n\nprint(\"ðŸ” Searching for best.pt files...\\n\")\n\n# Method 1: Search in fm_runs\nfor filepath in glob.glob(\"/kaggle/working/fm_runs/**/best.pt\", recursive=True):\n    size = os.path.getsize(filepath) / (1024*1024)\n    print(f\"âœ… Found: {filepath}\")\n    print(f\"   Size: {size:.1f} MB\\n\")\n\n# Method 2: Show directory structure\nprint(\"ðŸ“ Directory structure:\")\nfor root, dirs, files in os.walk(\"/kaggle/working/fm_runs\"):\n    level = root.replace(\"/kaggle/working/fm_runs\", \"\").count(os.sep)\n    indent = \" \" * 2 * level\n    print(f\"{indent}{os.path.basename(root)}/\")\n    subindent = \" \" * 2 * (level + 1)\n    for file in files[:5]:  # Show first 5 files\n        if file.endswith(\".pt\"):\n            print(f\"{subindent}ðŸ“„ {file}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T13:16:59.151434Z","iopub.status.busy":"2025-12-02T13:16:59.151102Z","iopub.status.idle":"2025-12-02T13:16:59.159359Z","shell.execute_reply":"2025-12-02T13:16:59.158433Z"},"papermill":{"duration":0.365953,"end_time":"2025-12-02T13:16:59.160484","exception":false,"start_time":"2025-12-02T13:16:58.794531","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ” Searching for best.pt files...\n","\n","âœ… Found: /kaggle/working/fm_runs/fm_warmup_teacher/weights/best.pt\n","   Size: 22.7 MB\n","\n","âœ… Found: /kaggle/working/fm_runs/fm_fixmatch_student/weights/best.pt\n","   Size: 22.7 MB\n","\n","ðŸ“ Directory structure:\n","fm_runs/\n","  fm_warmup_teacher/\n","    weights/\n","      ðŸ“„ best.pt\n","      ðŸ“„ last.pt\n","  fm_fixmatch_student/\n","    weights/\n","      ðŸ“„ best.pt\n","      ðŸ“„ last.pt\n"]}],"execution_count":13},{"cell_type":"code","source":"# ============================================================\n# COPY BEST MODELS TO ROOT FOR EASY ACCESS\n# ============================================================\nimport shutil\nimport os\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸ“¦ COPYING BEST MODELS TO ROOT\")\nprint(\"=\"*70)\n\n# Find and copy FixMatch best model\nfm_best_path = None\nfor root, dirs, files in os.walk(\"/kaggle/working/fm_runs\"):\n    if \"best.pt\" in files:\n        fm_best_path = os.path.join(root, \"best.pt\")\n        break\n\nif fm_best_path:\n    shutil.copy(fm_best_path, \"/kaggle/working/fixmatch_best.pt\")\n    print(f\"âœ… FixMatch: {fm_best_path}\")\n    print(f\"   â†’ Copied to: /kaggle/working/fixmatch_best.pt\")\nelse:\n    print(\"âŒ FixMatch best.pt not found!\")\n\n# List all files in root\nprint(f\"\\nðŸ“ Files in /kaggle/working/:\")\nfor item in os.listdir(\"/kaggle/working\"):\n    if item.endswith(\".pt\"):\n        size = os.path.getsize(f\"/kaggle/working/{item}\") / (1024*1024)\n        print(f\"   {item:30s} ({size:.1f} MB)\")\n\nprint(\"\\nâœ… Best model copied! Download 'fixmatch_best.pt' from Output panel.\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T13:16:59.918030Z","iopub.status.busy":"2025-12-02T13:16:59.917693Z","iopub.status.idle":"2025-12-02T13:16:59.938999Z","shell.execute_reply":"2025-12-02T13:16:59.938180Z"},"papermill":{"duration":0.446471,"end_time":"2025-12-02T13:16:59.940030","exception":false,"start_time":"2025-12-02T13:16:59.493559","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","ðŸ“¦ COPYING BEST MODELS TO ROOT\n","======================================================================\n","âœ… FixMatch: /kaggle/working/fm_runs/fm_warmup_teacher/weights/best.pt\n","   â†’ Copied to: /kaggle/working/fixmatch_best.pt\n","\n","ðŸ“ Files in /kaggle/working/:\n","   fixmatch_best.pt               (22.7 MB)\n","   yolov8s-seg.pt                 (22.8 MB)\n","   yolo11n.pt                     (5.4 MB)\n","\n","âœ… Best model copied! Download 'fixmatch_best.pt' from Output panel.\n"]}],"execution_count":14},{"cell_type":"code","source":"!pip -q install ultralytics --no-deps","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-12-02T16:09:03.472817Z","iopub.status.busy":"2025-12-02T16:09:03.472558Z","iopub.status.idle":"2025-12-02T16:09:08.452652Z","shell.execute_reply":"2025-12-02T16:09:08.451593Z","shell.execute_reply.started":"2025-12-02T16:09:03.472797Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h"]}],"execution_count":2},{"cell_type":"code","source":"%%writefile /kaggle/working/data.yaml\n# ============================================================\n# YOLOv12 Dataset Configuration for Instance Segmentation\n# ============================================================\n\ntrain: /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/train/images\nval: /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/images\ntest: /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/test/images\n# Number of classes\nnc: 1\n\n# Class names\nnames: ['Car-Damage']","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:09:10.746628Z","iopub.status.busy":"2025-12-02T16:09:10.746312Z","iopub.status.idle":"2025-12-02T16:09:10.752890Z","shell.execute_reply":"2025-12-02T16:09:10.752098Z","shell.execute_reply.started":"2025-12-02T16:09:10.746597Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /kaggle/working/data.yaml\n"]}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# CELL 2: IMPORTS & SETUP\n# ============================================================\nimport os\nimport glob\nimport random\nimport shutil\nimport yaml\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport gc\nimport torch\n\nfrom ultralytics import YOLO\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"MEAN TEACHER - SEMI-SUPERVISED INSTANCE SEGMENTATION\")\nprint(\"=\"*70)\nprint(\"âœ… All imports successful!\")\n\n# Verify CUDA\nprint(f\"\\nðŸ”§ System Info:\")\nprint(f\"   Python: {torch.__version__}\")\nprint(f\"   PyTorch: {torch.__version__}\")\nprint(f\"   CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:09:13.269870Z","iopub.status.busy":"2025-12-02T16:09:13.269602Z","iopub.status.idle":"2025-12-02T16:09:19.968303Z","shell.execute_reply":"2025-12-02T16:09:19.967612Z","shell.execute_reply.started":"2025-12-02T16:09:13.269849Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","\n","======================================================================\n","MEAN TEACHER - SEMI-SUPERVISED INSTANCE SEGMENTATION\n","======================================================================\n","âœ… All imports successful!\n","\n","ðŸ”§ System Info:\n","   Python: 2.6.0+cu124\n","   PyTorch: 2.6.0+cu124\n","   CUDA available: True\n","   GPU: Tesla T4\n"]}],"execution_count":4},{"cell_type":"code","source":"# ============================================================\n# CELL 3: CONFIGURATION SETTINGS\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"CONFIGURATION\")\nprint(\"=\"*70)\n\n# Dataset paths\nBASE_DATASET = \"/kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8\"\nNUM_CLASSES = 1\nCLASS_NAMES = [\"Car-Damage\"]\n\n# Model settings\nIMGSZ = 640\nDEVICE = 0  # Single GPU\n\n# Data split\nLABELED_FRACTION = 0.2  # 20% labeled, 80% unlabeled\n\n# Mean Teacher hyperparameters\nMT_WARMUP_EPOCHS = 40        # Warmup on labeled only\nMEAN_TEACHER_EPOCHS = 50     # SSL training epochs\nBATCH_SIZE = 4               # Per-image batch size\nMT_CONF = 0.6                # Confidence threshold for pseudo-labels\n\n# Pseudo-label settings\nPSEUDO_PERCENTAGE = 0.15     # Use 15% of unlabeled per epoch\n# PSEUDO_BATCH_SIZE will be calculated after data split\n\n# Working directories\nMT_LABELED_PATH = \"/kaggle/working/mt_labeled\"\nMT_UNLABELED_PATH = \"/kaggle/working/mt_unlabeled\"\nMT_PSEUDO_PATH = \"/kaggle/working/mt_pseudo\"\nMT_MERGED_PATH = \"/kaggle/working/mt_merged\"\n\nprint(f\"\\nðŸ“Š Settings:\")\nprint(f\"   Model: YOLOv8s-seg\")\nprint(f\"   Image size: {IMGSZ}\")\nprint(f\"   Device: GPU {DEVICE}\")\nprint(f\"   Labeled fraction: {LABELED_FRACTION*100}%\")\nprint(f\"   Warmup epochs: {MT_WARMUP_EPOCHS}\")\nprint(f\"   SSL epochs: {MEAN_TEACHER_EPOCHS}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   Confidence threshold: {MT_CONF}\")\nprint(f\"   Pseudo-label percentage: {PSEUDO_PERCENTAGE*100}%\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:09:22.956314Z","iopub.status.busy":"2025-12-02T16:09:22.955604Z","iopub.status.idle":"2025-12-02T16:09:22.963259Z","shell.execute_reply":"2025-12-02T16:09:22.962487Z","shell.execute_reply.started":"2025-12-02T16:09:22.956288Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","CONFIGURATION\n","======================================================================\n","\n","ðŸ“Š Settings:\n","   Model: YOLOv8s-seg\n","   Image size: 640\n","   Device: GPU 0\n","   Labeled fraction: 20.0%\n","   Warmup epochs: 40\n","   SSL epochs: 50\n","   Batch size: 4\n","   Confidence threshold: 0.6\n","   Pseudo-label percentage: 15.0%\n"]}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# CELL 4: CREATE DIRECTORY STRUCTURE\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"CREATING DIRECTORIES\")\nprint(\"=\"*70)\n\nfor path in [MT_LABELED_PATH, MT_UNLABELED_PATH, MT_PSEUDO_PATH, MT_MERGED_PATH]:\n    os.makedirs(f\"{path}/images\", exist_ok=True)\n    os.makedirs(f\"{path}/labels\", exist_ok=True)\n    print(f\"âœ… {path}\")\n\nprint(\"\\nâœ… All directories created!\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:09:28.317819Z","iopub.status.busy":"2025-12-02T16:09:28.317419Z","iopub.status.idle":"2025-12-02T16:09:28.326672Z","shell.execute_reply":"2025-12-02T16:09:28.325676Z","shell.execute_reply.started":"2025-12-02T16:09:28.317794Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","CREATING DIRECTORIES\n","======================================================================\n","âœ… /kaggle/working/mt_labeled\n","âœ… /kaggle/working/mt_unlabeled\n","âœ… /kaggle/working/mt_pseudo\n","âœ… /kaggle/working/mt_merged\n","\n","âœ… All directories created!\n"]}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# CELL 5: HELPER FUNCTION FOR SEGMENTATION LABELS\n# ============================================================\ndef write_seg_label_file(out_txt, classes, masks_xy, img_shape):\n    \"\"\"\n    Write YOLO segmentation format label file.\n    \n    Args:\n        out_txt: Output label file path\n        classes: List of class IDs\n        masks_xy: List of polygon coordinates (unnormalized)\n        img_shape: (height, width) of the image\n    \n    Format: <class_id> <x1> <y1> <x2> <y2> ... (normalized 0-1)\n    \"\"\"\n    h, w = img_shape\n    with open(out_txt, \"w\") as f:\n        for cls_id, poly in zip(classes, masks_xy):\n            if poly is None or len(poly) < 3:\n                continue\n            \n            poly = np.array(poly, dtype=np.float32)\n            \n            # Normalize coordinates to [0, 1]\n            poly[:, 0] = np.clip(poly[:, 0] / w, 0.0, 1.0)\n            poly[:, 1] = np.clip(poly[:, 1] / h, 0.0, 1.0)\n            \n            # Flatten polygon to string\n            coords = \" \".join([f\"{v:.6f}\" for v in poly.reshape(-1)])\n            \n            # Write: class_id x1 y1 x2 y2 ...\n            f.write(f\"{int(cls_id)} {coords}\\n\")\n\nprint(\"âœ… Helper function defined\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:09:32.157146Z","iopub.status.busy":"2025-12-02T16:09:32.156640Z","iopub.status.idle":"2025-12-02T16:09:32.163355Z","shell.execute_reply":"2025-12-02T16:09:32.162698Z","shell.execute_reply.started":"2025-12-02T16:09:32.157123Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Helper function defined\n"]}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# CELL 6: DATA SPLIT (20% LABELED, 80% UNLABELED)\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATA SPLITTING\")\nprint(\"=\"*70)\n\ntrain_images_dir = f\"{BASE_DATASET}/train/images\"\ntrain_labels_dir = f\"{BASE_DATASET}/train/labels\"\n\n# Get all training images\nall_train_imgs = [\n    p for p in glob.glob(f\"{train_images_dir}/*.*\")\n    if p.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n]\n\nprint(f\"\\nðŸ“¦ Total training images: {len(all_train_imgs)}\")\n\n# Shuffle with fixed seed for reproducibility\nrandom.seed(42)\nrandom.shuffle(all_train_imgs)\n\n# Split into labeled (20%) and unlabeled (80%)\nsplit_idx = int(len(all_train_imgs) * LABELED_FRACTION)\nlabeled_imgs = all_train_imgs[:split_idx]\nunlabeled_imgs = all_train_imgs[split_idx:]\n\nprint(f\"\\nðŸ“Š Split results:\")\nprint(f\"   Labeled (20%):   {len(labeled_imgs)} images\")\nprint(f\"   Unlabeled (80%): {len(unlabeled_imgs)} images\")\n\n# Calculate PSEUDO_BATCH_SIZE dynamically\nPSEUDO_BATCH_SIZE = int(len(unlabeled_imgs) * PSEUDO_PERCENTAGE)\nprint(f\"\\nðŸ“Š Pseudo-label strategy:\")\nprint(f\"   Using per epoch: {PSEUDO_BATCH_SIZE} ({PSEUDO_PERCENTAGE*100}%)\")\n\n# Copy labeled split\nprint(f\"\\nðŸ“ Copying labeled split...\")\nfor img_path in tqdm(labeled_imgs, desc=\"Labeled images\"):\n    base = os.path.basename(img_path)\n    lbl = base.replace(\".jpg\", \".txt\").replace(\".jpeg\", \".txt\").replace(\".png\", \".txt\")\n    \n    # Copy image\n    shutil.copy(img_path, f\"{MT_LABELED_PATH}/images/{base}\")\n    \n    # Copy label if exists\n    lbl_path = f\"{train_labels_dir}/{lbl}\"\n    if os.path.exists(lbl_path):\n        shutil.copy(lbl_path, f\"{MT_LABELED_PATH}/labels/{lbl}\")\n\n# Copy unlabeled split\nprint(f\"\\nðŸ“ Copying unlabeled split...\")\nfor img_path in tqdm(unlabeled_imgs, desc=\"Unlabeled images\"):\n    base = os.path.basename(img_path)\n    lbl = base.replace(\".jpg\", \".txt\").replace(\".jpeg\", \".txt\").replace(\".png\", \".txt\")\n    \n    # Copy image\n    shutil.copy(img_path, f\"{MT_UNLABELED_PATH}/images/{base}\")\n    \n    # Copy label (for reference, not used in training)\n    lbl_path = f\"{train_labels_dir}/{lbl}\"\n    if os.path.exists(lbl_path):\n        shutil.copy(lbl_path, f\"{MT_UNLABELED_PATH}/labels/{lbl}\")\n\nprint(f\"\\nâœ… Data split complete!\")\nprint(f\"   Labeled: {len(os.listdir(f'{MT_LABELED_PATH}/images'))} images\")\nprint(f\"   Unlabeled: {len(os.listdir(f'{MT_UNLABELED_PATH}/images'))} images\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:09:37.182515Z","iopub.status.busy":"2025-12-02T16:09:37.181954Z","iopub.status.idle":"2025-12-02T16:10:25.313996Z","shell.execute_reply":"2025-12-02T16:10:25.313326Z","shell.execute_reply.started":"2025-12-02T16:09:37.182488Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","DATA SPLITTING\n","======================================================================\n","\n","ðŸ“¦ Total training images: 3408\n","\n","ðŸ“Š Split results:\n","   Labeled (20%):   681 images\n","   Unlabeled (80%): 2727 images\n","\n","ðŸ“Š Pseudo-label strategy:\n","   Using per epoch: 409 (15.0%)\n","\n","ðŸ“ Copying labeled split...\n"]},{"name":"stderr","output_type":"stream","text":["Labeled images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 681/681 [00:09<00:00, 68.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","ðŸ“ Copying unlabeled split...\n"]},{"name":"stderr","output_type":"stream","text":["Unlabeled images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2727/2727 [00:37<00:00, 71.94it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","âœ… Data split complete!\n","   Labeled: 681 images\n","   Unlabeled: 2727 images\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# CELL 7: WARMUP PHASE - TRAIN ON LABELED DATA\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 1: WARMUP TRAINING (SUPERVISED)\")\nprint(\"=\"*70)\n\n# Create YAML for labeled data only\nMT_DATA_YAML_LABELED = \"/kaggle/working/mt_labeled.yaml\"\nwith open(MT_DATA_YAML_LABELED, \"w\") as f:\n    yaml.safe_dump({\n        \"train\": f\"{MT_LABELED_PATH}/images\",\n        \"val\": f\"{BASE_DATASET}/valid/images\",\n        \"test\": f\"{BASE_DATASET}/test/images\",\n        \"nc\": NUM_CLASSES,\n        \"names\": CLASS_NAMES,\n    }, f, sort_keys=False)\n\nprint(f\"\\nâœ… Created: {MT_DATA_YAML_LABELED}\")\n\n# Load pretrained YOLOv8s-seg model\nprint(f\"\\nðŸ“¦ Loading YOLOv8s-seg...\")\nmt_base_model = YOLO(\"yolov8s-seg.pt\")\nprint(f\"âœ… Model loaded\")\n\n# Train warmup model\nprint(f\"\\nðŸ”¥ Starting warmup training...\")\nprint(f\"   Epochs: {MT_WARMUP_EPOCHS}\")\nprint(f\"   Data: Labeled only ({len(labeled_imgs)} images)\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\n\nmt_warmup_results = mt_base_model.train(\n    data=MT_DATA_YAML_LABELED,\n    epochs=MT_WARMUP_EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH_SIZE,\n    device=DEVICE,\n    project=\"/kaggle/working/mt_runs\",\n    name=\"mt_warmup_student\",\n    exist_ok=True,\n    patience=10,\n    amp=True,\n    cache=False,\n    verbose=True,\n)\n\nMT_WARMUP_BEST = f\"{mt_warmup_results.save_dir}/weights/best.pt\"\nprint(f\"\\nâœ… Warmup complete!\")\nprint(f\"   Best model: {MT_WARMUP_BEST}\")\n\n\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T16:10:37.046541Z","iopub.status.busy":"2025-12-02T16:10:37.046236Z","iopub.status.idle":"2025-12-02T16:34:11.480067Z","shell.execute_reply":"2025-12-02T16:34:11.479137Z","shell.execute_reply.started":"2025-12-02T16:10:37.046512Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","PHASE 1: WARMUP TRAINING (SUPERVISED)\n","======================================================================\n","\n","âœ… Created: /kaggle/working/mt_labeled.yaml\n","\n","ðŸ“¦ Loading YOLOv8s-seg...\n","âœ… Model loaded\n","\n","ðŸ”¥ Starting warmup training...\n","   Epochs: 40\n","   Data: Labeled only (681 images)\n","   Batch size: 4\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_labeled.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_warmup_student, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_warmup_student, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 14.4MB/s 0.1s\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 411/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 63.8MB/s 0.1s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1156.3Â±263.0 MB/s, size: 38.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_labeled/labels... 681 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 681/681 1.2Kit/s 0.6s<0.1s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_labeled/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 7.0Â±2.1 MB/s, size: 36.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 208.8it/s 4.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_warmup_student/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_warmup_student\u001b[0m\n","Starting training for 40 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/40      1.37G      2.123      4.326      3.405      2.079          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 7.6it/s 22.4s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.0it/s 15.3s0.1s\n","                   all        974       1888     0.0934      0.119     0.0365    0.00963     0.0144     0.0657    0.00452   0.000897\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/40      1.67G      2.418      4.478      3.119       2.36          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.2it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.3it/s 14.7s0.1s\n","                   all        974       1888     0.0626      0.036     0.0146    0.00397     0.0304     0.0191    0.00488    0.00117\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/40      1.71G      2.434      4.429       3.19      2.396          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 8.9it/s 19.1s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.1it/s 15.1s0.1s\n","                   all        974       1888     0.0167       0.25     0.0187    0.00509     0.0142     0.0911    0.00836    0.00158\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/40      1.75G      2.451      4.526      3.229      2.402          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.2it/s 14.9s0.1s\n","                   all        974       1888    0.00625      0.351     0.0106    0.00304     0.0117      0.145    0.00583    0.00136\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/40      1.79G      2.389      4.459      3.238      2.403          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.1it/s 15.1s0.1s\n","                   all        974       1888     0.0492      0.099     0.0155    0.00432     0.0383     0.0678    0.00799    0.00177\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/40      1.83G      2.349      4.363      3.214      2.337          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.0it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.2it/s 14.9s0.1s\n","                   all        974       1888     0.0884      0.116     0.0327    0.00982     0.0705     0.0841      0.019    0.00435\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/40      1.87G      2.304      4.295      3.129      2.322          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.3it/s 14.7s0.1s\n","                   all        974       1888     0.0775     0.0651     0.0262    0.00773     0.0631     0.0466     0.0132      0.003\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/40      1.91G      2.268      4.304      3.087      2.284          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.2it/s 14.9s0.1s\n","                   all        974       1888     0.0975      0.044      0.028     0.0104     0.0935     0.0387     0.0197    0.00676\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/40      1.95G      2.214      4.212      3.046      2.279          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.3it/s 14.7s0.1s\n","                   all        974       1888      0.124      0.123     0.0375     0.0102     0.0897     0.0826     0.0196    0.00443\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/40         2G      2.149       4.11      3.061      2.233          0        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.2it/s 14.9s0.1s\n","                   all        974       1888      0.143      0.136     0.0743     0.0228      0.114     0.0959     0.0406     0.0102\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/40      2.06G      2.111      4.098      2.926      2.172          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.2it/s 18.6s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.4it/s 14.6s0.1s\n","                   all        974       1888       0.15      0.146     0.0605     0.0196      0.134      0.124     0.0434     0.0109\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/40      2.15G      2.097      4.068      2.914      2.165          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.2it/s 14.8s0.1s\n","                   all        974       1888      0.155      0.138     0.0716     0.0219      0.144      0.109     0.0512      0.012\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/40      2.21G      2.055      4.032      2.839      2.154          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888      0.232      0.161     0.0979     0.0312      0.192      0.127      0.065      0.016\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/40      2.26G      2.043      4.038       2.86      2.158          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888      0.163      0.181     0.0799     0.0258      0.134      0.143     0.0526     0.0124\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/40      2.35G      1.993      3.927      2.769      2.123          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.2it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.4it/s 14.6s0.1s\n","                   all        974       1888      0.173      0.183     0.0926     0.0311      0.153      0.159     0.0668     0.0177\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/40      2.41G      2.003      3.944      2.745      2.096          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888      0.228      0.175       0.12     0.0411      0.196      0.141      0.078     0.0212\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/40      2.49G      2.014      3.898       2.66      2.059          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.6it/s 14.3s0.1s\n","                   all        974       1888      0.252      0.172      0.129     0.0456      0.228      0.153      0.099     0.0284\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/40      2.54G      1.967      3.816       2.73      2.051          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.3it/s 14.6s0.1s\n","                   all        974       1888      0.211      0.189      0.116     0.0416      0.203      0.152     0.0886     0.0241\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/40      2.64G      1.919      3.804       2.63      2.015          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.4it/s 14.5s0.1s\n","                   all        974       1888       0.25      0.222      0.135     0.0468      0.218      0.182     0.0938     0.0246\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/40       2.7G      1.926      3.751      2.609      2.022          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.6it/s 14.2s0.1s\n","                   all        974       1888      0.221      0.217       0.11     0.0401      0.198      0.176     0.0807     0.0215\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/40      2.77G      1.946      3.812      2.614       2.01          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888      0.223      0.229      0.132     0.0486      0.208      0.184     0.0978      0.027\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/40      2.83G      1.886      3.725      2.573      1.989          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.4it/s 14.5s0.1s\n","                   all        974       1888      0.225       0.24      0.145      0.054      0.204      0.191      0.107     0.0299\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/40       2.9G      1.878      3.736      2.512      1.987          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888      0.269      0.232      0.172      0.061      0.238      0.184      0.121     0.0339\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/40      3.02G      1.853      3.623       2.49      1.942          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.3it/s 14.7s0.1s\n","                   all        974       1888      0.238      0.234      0.148     0.0575      0.226      0.182      0.114     0.0326\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/40      3.06G      1.847      3.649      2.493      1.943         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.0it/s 19.1s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.2it/s 14.8s0.1s\n","                   all        974       1888      0.264      0.269      0.152     0.0567      0.237      0.232      0.116     0.0328\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/40      3.15G      1.835      3.583      2.469      1.927          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.3s0.1s\n","                   all        974       1888      0.293      0.257      0.184     0.0697      0.259      0.216      0.141     0.0418\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/40      3.17G      1.843      3.567      2.386      1.922          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.6it/s 14.2s0.1s\n","                   all        974       1888       0.27      0.258      0.181     0.0677      0.242      0.215      0.135     0.0406\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/40      3.24G      1.794      3.578      2.426      1.904          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.4it/s 14.4s0.1s\n","                   all        974       1888      0.306      0.276      0.198     0.0776      0.292      0.247      0.161     0.0497\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/40      3.33G      1.778      3.539      2.349      1.892          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.3s0.1s\n","                   all        974       1888      0.339      0.269       0.21     0.0806        0.3      0.225      0.157     0.0468\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/40      3.39G      1.759      3.498       2.35      1.878          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.0it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.4it/s 14.4s0.1s\n","                   all        974       1888      0.328      0.271      0.213     0.0843      0.311      0.242      0.174     0.0523\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/40      3.43G      1.847      3.559      2.499      2.083          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 8.9it/s 19.3s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.3it/s 14.6s0.1s\n","                   all        974       1888      0.315      0.265      0.219     0.0822      0.282      0.227      0.157     0.0452\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/40      3.51G      1.832      3.481      2.384      2.055          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.0it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888      0.342      0.298      0.231     0.0925      0.318      0.256      0.184     0.0602\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/40      3.57G      1.801      3.446      2.293      2.033          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.7it/s 14.0s0.1s\n","                   all        974       1888      0.375      0.288      0.244     0.0986      0.341      0.254      0.195     0.0645\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/40      3.64G      1.777      3.318      2.237      2.022          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.6it/s 14.1s0.1s\n","                   all        974       1888      0.323      0.314       0.23     0.0927      0.301      0.274      0.181     0.0583\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/40      3.79G      1.776      3.304      2.179      2.005          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.7it/s 14.1s0.1s\n","                   all        974       1888      0.397      0.309      0.279      0.116      0.383      0.274      0.225     0.0766\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/40      3.84G      1.731      3.249      2.124      1.972          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.8s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.6it/s 14.3s0.1s\n","                   all        974       1888      0.415      0.318      0.297      0.127      0.392      0.279      0.243     0.0843\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/40      3.88G      1.697      3.225      2.109      1.952          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.1it/s 18.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.5it/s 14.4s0.1s\n","                   all        974       1888       0.44      0.309      0.301      0.129      0.423      0.283       0.25      0.086\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/40      3.91G      1.701       3.15      2.048      1.943          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.2it/s 18.6s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.7it/s 14.0s0.1s\n","                   all        974       1888      0.406      0.335      0.304      0.134      0.391      0.283      0.253     0.0906\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/40      3.99G      1.669      3.126      1.993      1.899          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.2it/s 18.6s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.7it/s 14.0s0.1s\n","                   all        974       1888      0.423      0.334      0.321       0.14      0.406      0.293      0.267     0.0959\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/40      4.05G      1.655       3.12      1.985       1.89          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 9.2it/s 18.7s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.7it/s 14.1s0.1s\n","                   all        974       1888      0.415      0.343      0.321      0.142      0.425      0.293      0.274     0.0972\n","\n","40 epochs completed in 0.379 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_warmup_student/weights/last.pt, 23.9MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_warmup_student/weights/best.pt, 23.9MB\n","\n","Validating /kaggle/working/mt_runs/mt_warmup_student/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.4it/s 13.0s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.416      0.343       0.32      0.142       0.42      0.294      0.273     0.0972\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_warmup_student\u001b[0m\n","\n","âœ… Warmup complete!\n","   Best model: /kaggle/working/mt_runs/mt_warmup_student/weights/best.pt\n"]}],"execution_count":9},{"cell_type":"code","source":"# ============================================================\n# CELL 8: MEAN TEACHER TRAINING LOOP\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 2: MEAN TEACHER SSL TRAINING\")\nprint(\"=\"*70)\n\n# Get unlabeled image paths\nunlabeled_imgs_list = [\n    p for p in glob.glob(f\"{MT_UNLABELED_PATH}/images/*.*\")\n    if p.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n]\n\nprint(f\"\\nðŸ“¦ Available unlabeled images: {len(unlabeled_imgs_list)}\")\nprint(f\"   Using per epoch: {PSEUDO_BATCH_SIZE}\")\nprint(f\"   Confidence threshold: {MT_CONF}\")\n\n# Track best model\nbest_map = 0.0\nbest_epoch = 0\nbest_model_path = \"/kaggle/working/mt_best.pt\"\n\n\n# ============================================================\n# TRACKING SETUP - Add this before the training loop\n# ============================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Initialize tracking dictionary\nmt_metrics_history = {\n    'epoch': [],\n    'train/box_loss': [],\n    'train/seg_loss': [],\n    'train/cls_loss': [],\n    'train/dfl_loss': [],\n    'val/box_loss': [],\n    'val/seg_loss': [],\n    'val/cls_loss': [],\n    'val/dfl_loss': [],\n    'metrics/precision(B)': [],\n    'metrics/recall(B)': [],\n    'metrics/mAP50(B)': [],\n    'metrics/mAP50-95(B)': [],\n    'metrics/precision(M)': [],\n    'metrics/recall(M)': [],\n    'metrics/mAP50(M)': [],\n    'metrics/mAP50-95(M)': [],\n}\n\nprint(\"âœ… Metrics tracking initialized\")\n\n\n\n# Training loop\nfor epoch in range(MEAN_TEACHER_EPOCHS):\n    print(\"\\n\" + \"=\"*70)\n    print(f\"EPOCH {epoch+1}/{MEAN_TEACHER_EPOCHS}\")\n    print(\"=\"*70)\n    \n    # ============================================================\n    # Step 1: Load Models (Student and Teacher)\n    # ============================================================\n    print(f\"\\nðŸ“¦ Loading models...\")\n    \n    if epoch == 0:\n        # First epoch: Both use warmup weights\n        student_model = YOLO(MT_WARMUP_BEST)\n        teacher_model = YOLO(MT_WARMUP_BEST)\n        print(f\"   Using warmup weights\")\n    else:\n        # Later epochs: Use previous epoch weights\n        prev_checkpoint = f\"/kaggle/working/mt_epoch_{epoch-1}.pt\"\n        if os.path.exists(prev_checkpoint):\n            student_model = YOLO(prev_checkpoint)\n            teacher_model = YOLO(prev_checkpoint)\n            print(f\"   Using epoch {epoch-1} weights\")\n        else:\n            student_model = YOLO(MT_WARMUP_BEST)\n            teacher_model = YOLO(MT_WARMUP_BEST)\n            print(f\"   Warning: Previous epoch not found, using warmup\")\n    \n    print(f\"âœ… Models loaded\")\n    \n    # ============================================================\n    # Step 2: Generate Pseudo-Labels with Teacher\n    # ============================================================\n    print(f\"\\nðŸ·ï¸  Generating pseudo-labels with teacher model...\")\n    \n    # Clear previous pseudo-labels\n    for f in glob.glob(f\"{MT_PSEUDO_PATH}/images/*\"):\n        os.remove(f)\n    for f in glob.glob(f\"{MT_PSEUDO_PATH}/labels/*\"):\n        os.remove(f)\n    \n    # Sample subset of unlabeled images\n    sample_size = min(PSEUDO_BATCH_SIZE, len(unlabeled_imgs_list))\n    sample_imgs = random.sample(unlabeled_imgs_list, sample_size)\n    \n    pseudo_count = 0\n    \n    for img_path in tqdm(sample_imgs, desc=f\"Teacher (confâ‰¥{MT_CONF})\"):\n        # Read image\n        img = cv2.imread(img_path)\n        if img is None:\n            continue\n        \n        # Teacher prediction\n        results = teacher_model.predict(\n            source=img,\n            imgsz=IMGSZ,\n            conf=MT_CONF,\n            save=False,\n            verbose=False,\n        )\n        \n        # Check if valid predictions\n        if not results or results[0].masks is None or len(results[0].boxes) == 0:\n            continue\n        \n        r = results[0]\n        classes = []\n        masks_xy = []\n        \n        # Extract high-confidence masks\n        for i in range(len(r.boxes)):\n            if r.boxes.conf[i] < MT_CONF:\n                continue\n            \n            # Get polygon\n            poly = r.masks.xy[i]\n            \n            # Handle multi-part polygons (keep largest)\n            if isinstance(poly, list):\n                areas = [cv2.contourArea(np.array(p, dtype=np.float32))\n                        for p in poly if len(p) >= 3]\n                if not areas:\n                    continue\n                poly = poly[int(np.argmax(areas))]\n            \n            # Validate polygon\n            if poly is None or len(poly) < 3:\n                continue\n            \n            # Get class ID\n            cls_id = int(r.boxes.cls[i].item()) if hasattr(r.boxes, \"cls\") else 0\n            \n            classes.append(cls_id)\n            masks_xy.append(poly)\n        \n        # Skip if no valid masks\n        if not masks_xy:\n            continue\n        \n        # Save pseudo-labeled image and label\n        base = os.path.splitext(os.path.basename(img_path))[0]\n        out_img = f\"{MT_PSEUDO_PATH}/images/{base}.jpg\"\n        out_lbl = f\"{MT_PSEUDO_PATH}/labels/{base}.txt\"\n        \n        # Write label file\n        write_seg_label_file(out_lbl, classes, masks_xy, img.shape[:2])\n        \n        # Copy image\n        shutil.copy(img_path, out_img)\n        \n        pseudo_count += 1\n    \n    print(f\"\\n   âœ… Generated {pseudo_count} pseudo-labeled images\")\n    \n    # ============================================================\n    # Step 3: Merge Labeled + Pseudo-Labeled Data\n    # ============================================================\n    print(f\"\\nðŸ“¦ Merging datasets...\")\n    \n    # Clear merged directory\n    for f in glob.glob(f\"{MT_MERGED_PATH}/images/*\"):\n        os.remove(f)\n    for f in glob.glob(f\"{MT_MERGED_PATH}/labels/*\"):\n        os.remove(f)\n    \n    # Copy labeled data\n    for src in [f\"{MT_LABELED_PATH}/images\", f\"{MT_PSEUDO_PATH}/images\"]:\n        for f in glob.glob(f\"{src}/*\"):\n            shutil.copy(f, f\"{MT_MERGED_PATH}/images/{os.path.basename(f)}\")\n    \n    for src in [f\"{MT_LABELED_PATH}/labels\", f\"{MT_PSEUDO_PATH}/labels\"]:\n        for f in glob.glob(f\"{src}/*\"):\n            shutil.copy(f, f\"{MT_MERGED_PATH}/labels/{os.path.basename(f)}\")\n    \n    labeled_count = len(os.listdir(f\"{MT_LABELED_PATH}/images\"))\n    total_count = len(os.listdir(f\"{MT_MERGED_PATH}/images\"))\n    \n    print(f\"   Labeled: {labeled_count}\")\n    print(f\"   Pseudo-labeled: {pseudo_count}\")\n    print(f\"   Total: {total_count}\")\n    print(f\"âœ… Datasets merged\")\n    \n    # Create YAML for merged data\n    yaml_path = \"/kaggle/working/mt_merged.yaml\"\n    with open(yaml_path, \"w\") as f:\n        yaml.safe_dump({\n            \"train\": f\"{MT_MERGED_PATH}/images\",\n            \"val\": f\"{BASE_DATASET}/valid/images\",\n            \"test\": f\"{BASE_DATASET}/test/images\",\n            \"nc\": NUM_CLASSES,\n            \"names\": CLASS_NAMES,\n        }, f, sort_keys=False)\n    \n    # ============================================================\n    # Step 4: Train Student on Labeled + Pseudo-Labeled\n    # ============================================================\n    print(f\"\\nðŸŽ“ Training student model...\")\n    print(f\"   Training data: {total_count} images\")\n    print(f\"   Epochs: 1 (incremental)\")\n    \n    train_result = student_model.train(\n        data=yaml_path,\n        epochs=1,\n        imgsz=IMGSZ,\n        batch=BATCH_SIZE,\n        device=DEVICE,\n        project=\"/kaggle/working/mt_runs\",\n        name=f\"mt_epoch_{epoch}\",\n        exist_ok=True,\n        resume=False,\n        amp=True,\n        verbose=False,\n        cache=False,\n    )\n    \n    # Save epoch checkpoint\n    epoch_checkpoint = f\"/kaggle/working/mt_epoch_{epoch}.pt\"\n    student_model.save(epoch_checkpoint)\n    print(f\"âœ… Checkpoint saved: {epoch_checkpoint}\")\n    \n       # ============================================================\n    # Step 5: Validate Student Model\n    # ============================================================\n    print(f\"\\nðŸ“Š Validating student model...\")\n    \n    val_result = student_model.val(split=\"val\", verbose=False)\n    \n    # Get metrics\n    current_map50 = val_result.seg.map50\n    current_map = val_result.seg.map\n    \n    print(f\"\\n   ðŸ“ˆ Metrics:\")\n    print(f\"      Mask mAP@0.5:      {current_map50:.4f}\")\n    print(f\"      Mask mAP@0.5:0.95: {current_map:.4f}\")\n    \n    # ============================================================\n    # COLLECT METRICS FOR THIS EPOCH - ADD THIS SECTION\n    # ============================================================\n    # Read the results.csv from this epoch's training\n    epoch_results_csv = f\"/kaggle/working/mt_runs/mt_epoch_{epoch}/results.csv\"\n    \n    if os.path.exists(epoch_results_csv):\n        epoch_df = pd.read_csv(epoch_results_csv)\n        epoch_df.columns = epoch_df.columns.str.strip()\n        \n        # Get the last row (final values for this epoch)\n        last_row = epoch_df.iloc[-1]\n        \n        # Store metrics\n        mt_metrics_history['epoch'].append(epoch + 1)\n        mt_metrics_history['train/box_loss'].append(last_row.get('train/box_loss', 0))\n        mt_metrics_history['train/seg_loss'].append(last_row.get('train/seg_loss', 0))\n        mt_metrics_history['train/cls_loss'].append(last_row.get('train/cls_loss', 0))\n        mt_metrics_history['train/dfl_loss'].append(last_row.get('train/dfl_loss', 0))\n        mt_metrics_history['val/box_loss'].append(last_row.get('val/box_loss', 0))\n        mt_metrics_history['val/seg_loss'].append(last_row.get('val/seg_loss', 0))\n        mt_metrics_history['val/cls_loss'].append(last_row.get('val/cls_loss', 0))\n        mt_metrics_history['val/dfl_loss'].append(last_row.get('val/dfl_loss', 0))\n        mt_metrics_history['metrics/precision(B)'].append(last_row.get('metrics/precision(B)', 0))\n        mt_metrics_history['metrics/recall(B)'].append(last_row.get('metrics/recall(B)', 0))\n        mt_metrics_history['metrics/mAP50(B)'].append(last_row.get('metrics/mAP50(B)', 0))\n        mt_metrics_history['metrics/mAP50-95(B)'].append(last_row.get('metrics/mAP50-95(B)', 0))\n        mt_metrics_history['metrics/precision(M)'].append(last_row.get('metrics/precision(M)', 0))\n        mt_metrics_history['metrics/recall(M)'].append(last_row.get('metrics/recall(M)', 0))\n        mt_metrics_history['metrics/mAP50(M)'].append(last_row.get('metrics/mAP50(M)', 0))\n        mt_metrics_history['metrics/mAP50-95(M)'].append(last_row.get('metrics/mAP50-95(M)', 0))\n        \n        print(f\"   âœ… Metrics collected for epoch {epoch + 1}\")\n    \n    # Track best model\n    if current_map50 > best_map:\n        best_map = current_map50\n        best_epoch = epoch + 1\n        student_model.save(best_model_path)\n        print(f\"\\n   ðŸŽ¯ NEW BEST MODEL!\")\n        print(f\"      Best mAP@0.5: {best_map:.4f}\")\n        print(f\"      Saved to: {best_model_path}\")\n    else:\n        print(f\"\\n   Current best: {best_map:.4f} (epoch {best_epoch})\")\n\n    \n    \n    # ============================================================\n    # Step 6: Cleanup\n    # ============================================================\n    del student_model\n    del teacher_model\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    print(f\"\\nâœ… Epoch {epoch+1} complete!\")\n\n# Training summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"MEAN TEACHER TRAINING COMPLETE\")\nprint(\"=\"*70)\n\nprint(f\"\\nðŸ† Best Results:\")\nprint(f\"   Best mAP@0.5: {best_map:.4f}\")\nprint(f\"   Best epoch: {best_epoch}/{MEAN_TEACHER_EPOCHS}\")\nprint(f\"   Best model: {best_model_path}\")\n\n\n# ============================================================\n# ðŸ‘ˆ ADD THIS - CREATE COMBINED PLOT\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"CREATING COMBINED TRAINING RESULTS PLOT\")\nprint(\"=\"*70)\n\nmt_results_df = pd.DataFrame(mt_metrics_history)\nmt_results_df.to_csv('/kaggle/working/meanteacher_combined_results.csv', index=False)\n\nfig, axes = plt.subplots(4, 4, figsize=(20, 20))\nfig.suptitle('Mean Teacher SSL Training Results', fontsize=16, fontweight='bold')\n\n# Row 1: Training losses\naxes[0, 0].plot(mt_results_df['epoch'], mt_results_df['train/box_loss'], marker='o')\naxes[0, 0].set_title('train/box_loss')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(mt_results_df['epoch'], mt_results_df['train/seg_loss'], marker='o')\naxes[0, 1].set_title('train/seg_loss')\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[0, 2].plot(mt_results_df['epoch'], mt_results_df['train/cls_loss'], marker='o')\naxes[0, 2].set_title('train/cls_loss')\naxes[0, 2].grid(True, alpha=0.3)\n\naxes[0, 3].plot(mt_results_df['epoch'], mt_results_df['train/dfl_loss'], marker='o')\naxes[0, 3].set_title('train/dfl_loss')\naxes[0, 3].grid(True, alpha=0.3)\n\n# Row 2: Validation losses\naxes[1, 0].plot(mt_results_df['epoch'], mt_results_df['val/box_loss'], marker='o')\naxes[1, 0].set_title('val/box_loss')\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].plot(mt_results_df['epoch'], mt_results_df['val/seg_loss'], marker='o')\naxes[1, 1].set_title('val/seg_loss')\naxes[1, 1].grid(True, alpha=0.3)\n\naxes[1, 2].plot(mt_results_df['epoch'], mt_results_df['val/cls_loss'], marker='o')\naxes[1, 2].set_title('val/cls_loss')\naxes[1, 2].grid(True, alpha=0.3)\n\naxes[1, 3].plot(mt_results_df['epoch'], mt_results_df['val/dfl_loss'], marker='o')\naxes[1, 3].set_title('val/dfl_loss')\naxes[1, 3].grid(True, alpha=0.3)\n\n# Row 3: Box metrics\naxes[2, 0].plot(mt_results_df['epoch'], mt_results_df['metrics/precision(B)'], marker='o')\naxes[2, 0].set_title('metrics/precision(B)')\naxes[2, 0].grid(True, alpha=0.3)\n\naxes[2, 1].plot(mt_results_df['epoch'], mt_results_df['metrics/recall(B)'], marker='o')\naxes[2, 1].set_title('metrics/recall(B)')\naxes[2, 1].grid(True, alpha=0.3)\n\naxes[2, 2].plot(mt_results_df['epoch'], mt_results_df['metrics/mAP50(B)'], marker='o')\naxes[2, 2].set_title('metrics/mAP50(B)')\naxes[2, 2].grid(True, alpha=0.3)\n\naxes[2, 3].plot(mt_results_df['epoch'], mt_results_df['metrics/mAP50-95(B)'], marker='o')\naxes[2, 3].set_title('metrics/mAP50-95(B)')\naxes[2, 3].grid(True, alpha=0.3)\n\n# Row 4: Mask metrics\naxes[3, 0].plot(mt_results_df['epoch'], mt_results_df['metrics/precision(M)'], marker='o')\naxes[3, 0].set_title('metrics/precision(M)')\naxes[3, 0].grid(True, alpha=0.3)\n\naxes[3, 1].plot(mt_results_df['epoch'], mt_results_df['metrics/recall(M)'], marker='o')\naxes[3, 1].set_title('metrics/recall(M)')\naxes[3, 1].grid(True, alpha=0.3)\n\naxes[3, 2].plot(mt_results_df['epoch'], mt_results_df['metrics/mAP50(M)'], marker='o')\naxes[3, 2].set_title('metrics/mAP50(M)')\naxes[3, 2].grid(True, alpha=0.3)\n\naxes[3, 3].plot(mt_results_df['epoch'], mt_results_df['metrics/mAP50-95(M)'], marker='o')\naxes[3, 3].set_title('metrics/mAP50-95(M)')\naxes[3, 3].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/meanteacher_combined_results.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\nâœ… Combined results plot saved!\")\n# ============================================================\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T18:50:01.857918Z","iopub.status.busy":"2025-12-02T18:50:01.857091Z","iopub.status.idle":"2025-12-02T20:15:57.336592Z","shell.execute_reply":"2025-12-02T20:15:57.335807Z","shell.execute_reply.started":"2025-12-02T18:50:01.857895Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","PHASE 2: MEAN TEACHER SSL TRAINING\n","======================================================================\n","\n","ðŸ“¦ Available unlabeled images: 2727\n","   Using per epoch: 409\n","   Confidence threshold: 0.6\n","\n","======================================================================\n","EPOCH 1/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using warmup weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 65 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 65\n","   Total: 746\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 746 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_runs/mt_warmup_student/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 973.9Â±419.8 MB/s, size: 34.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 746 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 746/746 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±1.2 ms, read: 25.7Â±10.1 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 411.4it/s 2.4s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_0/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_0\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1       4.7G      1.716      3.357       2.24      1.828         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 8.2it/s 22.9s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.1it/s 17.1s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.229      0.301      0.175      0.071      0.218      0.234      0.132     0.0429\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_0/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_0/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_0/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.8s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.229      0.302      0.175     0.0708      0.215      0.237      0.132     0.0428\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_0\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_0.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.0Â±10.7 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 543.2it/s 1.8s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.5s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.227      0.308      0.173      0.071      0.214      0.239       0.13     0.0426\n","Speed: 1.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val65\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1304\n","      Mask mAP@0.5:0.95: 0.0426\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1304\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 1 complete!\n","\n","======================================================================\n","EPOCH 2/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 0 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 28 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 28\n","   Total: 709\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 709 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_0.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 817.7Â±322.3 MB/s, size: 30.5 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 709 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 709/709 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.8Â±8.0 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 693.4it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_1/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_1\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.96G      1.722      3.374       2.27      1.819          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 178/178 8.2it/s 21.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.8s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.316      0.246      0.205     0.0755      0.274       0.21      0.157     0.0449\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_1/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_1/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_1/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.8s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.317      0.247      0.205     0.0755      0.275       0.21      0.157      0.045\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_1\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_1.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 22.9Â±6.2 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 535.0it/s 1.8s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 22.1s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.315      0.247      0.205     0.0756      0.275       0.21      0.157      0.045\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val66\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1575\n","      Mask mAP@0.5:0.95: 0.0450\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1575\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 2 complete!\n","\n","======================================================================\n","EPOCH 3/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 1 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 6 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 6\n","   Total: 687\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 687 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_1.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 905.6Â±116.8 MB/s, size: 35.8 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 687 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 687/687 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.0Â±8.5 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 671.9it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_2\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.94G      1.753      3.412      2.258      1.861         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 172/172 8.2it/s 20.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 16.9s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.273      0.274      0.181       0.07      0.256      0.253      0.151     0.0476\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_2/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_2/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_2/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.9it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.273      0.274      0.181     0.0699      0.257      0.253      0.151     0.0475\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_2\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_2.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.6Â±6.2 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 554.8it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 22.1s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.273      0.276      0.181     0.0702      0.259      0.252      0.152     0.0474\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val67\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1516\n","      Mask mAP@0.5:0.95: 0.0474\n","\n","   Current best: 0.1575 (epoch 2)\n","\n","âœ… Epoch 3 complete!\n","\n","======================================================================\n","EPOCH 4/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 2 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 12 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 12\n","   Total: 693\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 693 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_2.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 934.4Â±168.7 MB/s, size: 32.5 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 693 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 693/693 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.9Â±8.2 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 693.1it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_3\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.719      3.356      2.243      1.821          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 8.3it/s 20.9s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.7s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.256      0.272      0.159     0.0622      0.246      0.237      0.133     0.0424\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_3/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_3/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_3/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.256      0.275       0.16     0.0622      0.246      0.236      0.132     0.0425\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_3\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_3.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.5Â±6.2 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 576.1it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.8s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.257      0.272       0.16     0.0623      0.247      0.237      0.132     0.0424\n","Speed: 1.1ms preprocess, 14.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val68\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1324\n","      Mask mAP@0.5:0.95: 0.0424\n","\n","   Current best: 0.1575 (epoch 2)\n","\n","âœ… Epoch 4 complete!\n","\n","======================================================================\n","EPOCH 5/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 3 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 20 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 20\n","   Total: 701\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 701 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_3.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 961.0Â±261.0 MB/s, size: 32.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 701 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 701/701 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.5Â±10.2 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 695.4it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_4/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_4\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.761      3.348      2.239      1.839          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 176/176 8.4it/s 21.0s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.315      0.272      0.224     0.0861      0.272      0.229      0.163     0.0508\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_4/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_4/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_4/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.2s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.315      0.272      0.223      0.086      0.272      0.229      0.163     0.0508\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_4\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_4.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.2Â±7.8 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 558.1it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.8s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.315      0.271      0.223     0.0861      0.272      0.229      0.163     0.0508\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val69\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1626\n","      Mask mAP@0.5:0.95: 0.0508\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1626\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 5 complete!\n","\n","======================================================================\n","EPOCH 6/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 4 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 8 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 8\n","   Total: 689\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 689 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_4.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 659.6Â±132.4 MB/s, size: 35.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 689 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 689/689 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.3Â±7.5 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 641.7it/s 1.5s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_5/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_5\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.719      3.358      2.236       1.81          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 8.3it/s 20.7s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.8s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.276      0.285       0.18     0.0724      0.263      0.229      0.142     0.0463\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_5/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_5/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_5/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.9it/s 13.7s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.278      0.284      0.181     0.0723      0.264       0.23      0.142     0.0464\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_5\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_5.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.1Â±10.2 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 519.7it/s 1.9s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.3s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.278      0.284      0.181     0.0722      0.262      0.229      0.142     0.0463\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val70\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1421\n","      Mask mAP@0.5:0.95: 0.0463\n","\n","   Current best: 0.1626 (epoch 5)\n","\n","âœ… Epoch 6 complete!\n","\n","======================================================================\n","EPOCH 7/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 5 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 20 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 20\n","   Total: 701\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 701 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_5.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 940.8Â±313.0 MB/s, size: 31.8 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 701 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 701/701 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.8Â±7.5 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 604.4it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_6/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_6\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.741      3.281      2.213      1.842          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 176/176 8.3it/s 21.1s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.3s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.32      0.272        0.2     0.0793      0.292      0.239      0.162     0.0529\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_6/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_6/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_6/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.3s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.32      0.272      0.201     0.0793      0.291       0.24      0.161     0.0528\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_6\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_6.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.7Â±8.9 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 428.6it/s 2.3s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.32      0.272      0.201     0.0795      0.291       0.24      0.161     0.0529\n","Speed: 1.0ms preprocess, 14.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val71\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1606\n","      Mask mAP@0.5:0.95: 0.0529\n","\n","   Current best: 0.1626 (epoch 5)\n","\n","âœ… Epoch 7 complete!\n","\n","======================================================================\n","EPOCH 8/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 6 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 12 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 12\n","   Total: 693\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 693 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_6.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 867.6Â±214.7 MB/s, size: 33.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 693 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 693/693 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.6Â±6.0 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 649.2it/s 1.5s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_7/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_7\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G       1.69      3.295      2.145      1.804          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 8.4it/s 20.8s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 17.0s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.25      0.313      0.191     0.0755      0.247       0.27      0.165     0.0521\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_7/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_7/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_7/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.8s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.249      0.315      0.191     0.0755      0.244      0.281      0.165      0.052\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 3.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_7\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_7.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.6Â±12.7 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 432.8it/s 2.3s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.5s0.4ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.249      0.316      0.191     0.0756      0.247       0.27      0.165     0.0522\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val72\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1648\n","      Mask mAP@0.5:0.95: 0.0522\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1648\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 8 complete!\n","\n","======================================================================\n","EPOCH 9/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 7 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 43 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 43\n","   Total: 724\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 724 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_7.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1033.6Â±317.6 MB/s, size: 39.2 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 724 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 724/724 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 21.9Â±11.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 598.7it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_8/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_8\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.718      3.338      2.233      1.821          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 181/181 8.3it/s 21.7s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.1it/s 17.1s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.323      0.279      0.222     0.0881      0.306      0.252       0.18      0.057\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_8/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_8/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_8/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.9s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.323      0.279      0.222     0.0879      0.308      0.251       0.18      0.057\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 3.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_8\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_8.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.0Â±6.9 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 459.5it/s 2.1s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.5s0.4ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.326      0.279      0.223      0.088      0.309      0.251       0.18      0.057\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val73\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1799\n","      Mask mAP@0.5:0.95: 0.0570\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1799\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 9 complete!\n","\n","======================================================================\n","EPOCH 10/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 8 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 6 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 6\n","   Total: 687\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 687 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_8.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_9, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_9, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 598.8Â±470.0 MB/s, size: 34.5 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 687 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 687/687 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.7Â±15.5 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 581.4it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_9/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_9\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.687      3.221      2.108      1.784         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 172/172 8.3it/s 20.6s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.7s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.329      0.298      0.211     0.0799      0.289      0.238      0.148     0.0456\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_9/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_9/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_9/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.9s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.328      0.297      0.211     0.0799      0.287      0.237      0.147     0.0454\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_9\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_9.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.1Â±7.0 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 497.5it/s 2.0s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.3s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.329      0.298      0.211     0.0795      0.288      0.238      0.148     0.0456\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val74\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1478\n","      Mask mAP@0.5:0.95: 0.0456\n","\n","   Current best: 0.1799 (epoch 9)\n","\n","âœ… Epoch 10 complete!\n","\n","======================================================================\n","EPOCH 11/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 9 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 26 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 26\n","   Total: 707\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 707 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_9.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_10, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 882.0Â±223.4 MB/s, size: 32.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 707 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 707/707 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 19.6Â±15.1 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 617.7it/s 1.6s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_10/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_10\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.95G       1.72      3.294      2.138      1.834         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 177/177 8.4it/s 21.2s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 16.9s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.299      0.276      0.207     0.0856      0.274      0.229      0.162     0.0537\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_10/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_10/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_10/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.8s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.299      0.275      0.206     0.0854      0.273      0.229      0.162     0.0536\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_10\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_10.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.8Â±7.9 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 561.6it/s 1.7s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.2s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.299      0.276      0.207     0.0855      0.274      0.229      0.161     0.0533\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val75\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1612\n","      Mask mAP@0.5:0.95: 0.0533\n","\n","   Current best: 0.1799 (epoch 9)\n","\n","âœ… Epoch 11 complete!\n","\n","======================================================================\n","EPOCH 12/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 10 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 55 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 55\n","   Total: 736\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 736 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_11, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 940.3Â±249.8 MB/s, size: 33.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 736 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 736/736 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.3Â±12.1 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 609.8it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_11/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_11\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.688      3.212      2.115      1.786         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 184/184 8.3it/s 22.0s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.5s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.375      0.279      0.247      0.106      0.321      0.231      0.182      0.061\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_11/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_11/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_11/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.372       0.28      0.246      0.106      0.322      0.231      0.182     0.0609\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_11\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_11.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.9Â±11.2 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 530.7it/s 1.8s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 22.1s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.371       0.28      0.247      0.106      0.322      0.232      0.183     0.0607\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val76\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1826\n","      Mask mAP@0.5:0.95: 0.0607\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1826\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 12 complete!\n","\n","======================================================================\n","EPOCH 13/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 11 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 32 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 32\n","   Total: 713\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 713 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_11.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_12, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_12, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 962.5Â±259.5 MB/s, size: 30.5 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 713 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 713/713 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 22.3Â±12.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 651.7it/s 1.5s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_12/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_12\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.99G      1.686      3.287      2.135      1.801          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 179/179 8.3it/s 21.5s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.7s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.368      0.306      0.254      0.105      0.344      0.268        0.2     0.0648\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_12/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_12/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_12/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.9it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.371      0.305      0.255      0.105      0.343      0.266      0.199     0.0647\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_12\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_12.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 31.2Â±6.3 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 591.0it/s 1.6s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 22.0s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.37      0.305      0.254      0.105      0.344      0.267      0.199     0.0645\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val77\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1995\n","      Mask mAP@0.5:0.95: 0.0645\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.1995\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 13 complete!\n","\n","======================================================================\n","EPOCH 14/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 12 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 25 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 25\n","   Total: 706\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 706 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_12.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_13, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 804.7Â±281.3 MB/s, size: 31.0 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 706 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 706/706 1.1Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.8Â±7.8 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 719.8it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_13/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_13\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.94G      1.694      3.202      2.121      1.808          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 177/177 8.2it/s 21.5s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.339      0.307      0.221      0.088      0.307      0.253      0.174      0.056\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_13/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_13/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_13/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.3s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.343      0.306       0.22     0.0883      0.307      0.253      0.173     0.0559\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_13\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_13.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 31.8Â±10.5 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 606.2it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.342      0.306      0.221      0.088      0.307      0.253      0.174     0.0562\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val78\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1740\n","      Mask mAP@0.5:0.95: 0.0562\n","\n","   Current best: 0.1995 (epoch 13)\n","\n","âœ… Epoch 14 complete!\n","\n","======================================================================\n","EPOCH 15/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 13 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 6 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 6\n","   Total: 687\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 687 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_13.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_14, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_14, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 979.7Â±155.8 MB/s, size: 36.8 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 687 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 687/687 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.9Â±9.7 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 716.3it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_14/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_14\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.654      3.186      2.085      1.775         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 172/172 8.2it/s 20.9s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 17.1s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.364      0.305      0.254      0.106      0.344      0.273      0.212     0.0688\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_14/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_14/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_14/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.9s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.361      0.306      0.254      0.105      0.343      0.275      0.211     0.0686\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_14\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_14.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.3Â±9.6 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 585.2it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.2s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.365      0.305      0.254      0.105      0.344      0.274      0.211     0.0683\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val79\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2111\n","      Mask mAP@0.5:0.95: 0.0683\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2111\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 15 complete!\n","\n","======================================================================\n","EPOCH 16/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 14 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 18 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 18\n","   Total: 699\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 699 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_14.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_15, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_15, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 927.4Â±250.3 MB/s, size: 32.2 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 699 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 699/699 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.5Â±9.3 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 743.6it/s 1.3s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_15/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_15\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1       1.9G       1.65      3.198       2.05      1.757         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 175/175 8.3it/s 21.2s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.3s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.353       0.28      0.251      0.109      0.317      0.258      0.208     0.0693\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_15/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_15/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_15/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.3it/s 13.1s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.352       0.28      0.251      0.109      0.317      0.259      0.208     0.0691\n","Speed: 0.3ms preprocess, 5.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_15\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_15.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.2Â±9.1 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 612.5it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.352       0.28      0.251      0.109      0.318      0.259      0.209     0.0691\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val80\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2095\n","      Mask mAP@0.5:0.95: 0.0691\n","\n","   Current best: 0.2111 (epoch 15)\n","\n","âœ… Epoch 16 complete!\n","\n","======================================================================\n","EPOCH 17/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 15 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 38 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 38\n","   Total: 719\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 719 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_15.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 924.6Â±252.2 MB/s, size: 33.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 719 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 29.3Â±7.4 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 726.7it/s 1.3s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_16/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_16\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.656      3.188      2.052      1.779          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 180/180 8.1it/s 22.3s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 17.0s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.355      0.294      0.247      0.104      0.344      0.247      0.205     0.0677\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_16/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_16/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_16/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.355      0.295      0.248      0.104      0.348      0.243      0.205     0.0678\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_16\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_16.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 30.2Â±9.6 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 614.0it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.8s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.352      0.297      0.248      0.104      0.341      0.246      0.204     0.0676\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val81\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2043\n","      Mask mAP@0.5:0.95: 0.0676\n","\n","   Current best: 0.2111 (epoch 15)\n","\n","âœ… Epoch 17 complete!\n","\n","======================================================================\n","EPOCH 18/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 16 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 25 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 25\n","   Total: 706\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 706 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_16.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_17, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_17, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1022.7Â±310.7 MB/s, size: 37.1 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 706 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 706/706 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.8Â±8.1 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 708.5it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_17/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_17\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.632       3.18      1.998      1.739          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 177/177 8.3it/s 21.4s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.1it/s 17.1s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.327      0.305      0.239      0.101      0.322      0.284      0.209     0.0714\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_17/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_17/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_17/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.8s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.329      0.305       0.24      0.101      0.322      0.284      0.209     0.0713\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_17\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_17.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.9Â±4.9 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 583.8it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.4s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.323      0.315      0.239      0.101      0.321      0.284      0.209     0.0709\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val82\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2087\n","      Mask mAP@0.5:0.95: 0.0709\n","\n","   Current best: 0.2111 (epoch 15)\n","\n","âœ… Epoch 18 complete!\n","\n","======================================================================\n","EPOCH 19/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 17 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 121 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 121\n","   Total: 802\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 802 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_17.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_18, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_18, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 775.6Â±248.8 MB/s, size: 28.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 802 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 802/802 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.2Â±9.0 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 734.4it/s 1.3s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_18/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_18\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.89G      1.632      3.118      2.015      1.727         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 201/201 8.3it/s 24.3s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.8s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.359      0.294      0.244      0.101      0.341      0.258      0.206     0.0625\n","\n","1 epochs completed in 0.013 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_18/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_18/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_18/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.359      0.294      0.245      0.101       0.34      0.259      0.206     0.0626\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_18\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_18.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 33.6Â±8.3 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 590.8it/s 1.6s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 22.0s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.36      0.294      0.245      0.101       0.34      0.259      0.205     0.0625\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val83\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2055\n","      Mask mAP@0.5:0.95: 0.0625\n","\n","   Current best: 0.2111 (epoch 15)\n","\n","âœ… Epoch 19 complete!\n","\n","======================================================================\n","EPOCH 20/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 18 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 65 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 65\n","   Total: 746\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 746 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_18.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_19, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_19, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 947.2Â±408.8 MB/s, size: 36.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 746 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 746/746 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.9Â±8.8 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 730.7it/s 1.3s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_19/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_19\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.655      3.206      2.012      1.757          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 8.3it/s 22.6s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 16.9s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.428      0.302      0.282      0.122      0.399      0.275      0.236     0.0815\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_19/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_19/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_19/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.9it/s 13.8s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.431      0.306      0.283      0.122      0.399      0.276      0.236     0.0816\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_19\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_19.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 29.0Â±9.0 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 562.5it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.3s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.429      0.302      0.283      0.122      0.397      0.276      0.236     0.0814\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val84\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2359\n","      Mask mAP@0.5:0.95: 0.0814\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2359\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 20 complete!\n","\n","======================================================================\n","EPOCH 21/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 19 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 85 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 85\n","   Total: 766\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 766 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_19.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_20, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_20, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 910.8Â±295.0 MB/s, size: 32.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 766 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 766/766 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 29.3Â±8.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 700.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_20/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_20\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.636       3.15      1.996      1.736          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 192/192 8.3it/s 23.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.6s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.396      0.318      0.282      0.112      0.344      0.274       0.22     0.0738\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_20/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_20/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_20/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.6s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.396      0.318      0.282      0.112      0.345      0.275      0.221     0.0739\n","Speed: 0.3ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_20\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_20.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 33.2Â±8.3 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 541.0it/s 1.8s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.398      0.318      0.282      0.112      0.346      0.275      0.222      0.074\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val85\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2223\n","      Mask mAP@0.5:0.95: 0.0740\n","\n","   Current best: 0.2359 (epoch 20)\n","\n","âœ… Epoch 21 complete!\n","\n","======================================================================\n","EPOCH 22/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 20 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 61 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 61\n","   Total: 742\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 742 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_20.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_21, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_21, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 905.7Â±320.9 MB/s, size: 31.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 742 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 742/742 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.4Â±8.4 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 698.9it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_21/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_21\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.641      3.064      1.991      1.757          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 186/186 8.2it/s 22.6s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 16.9s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.364      0.302      0.267      0.113      0.349      0.286      0.233     0.0806\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_21/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_21/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_21/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.9it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.363      0.302      0.267      0.113      0.351      0.285      0.233     0.0806\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_21\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_21.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 31.2Â±6.9 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 587.3it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 22.1s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.364      0.302      0.267      0.113      0.349      0.285      0.234     0.0807\n","Speed: 1.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val86\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2342\n","      Mask mAP@0.5:0.95: 0.0807\n","\n","   Current best: 0.2359 (epoch 20)\n","\n","âœ… Epoch 22 complete!\n","\n","======================================================================\n","EPOCH 23/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 21 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 109 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 109\n","   Total: 790\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 790 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_21.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_22, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_22, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 902.3Â±227.4 MB/s, size: 28.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 790 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 790/790 1.1Kit/s 0.7s<0.1s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.2Â±5.9 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 614.8it/s 1.6s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_22/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_22\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.95G      1.626       3.05      1.967      1.736          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 8.3it/s 23.8s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.2it/s 17.0s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.445       0.31      0.297      0.122      0.419      0.272      0.246     0.0836\n","\n","1 epochs completed in 0.013 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_22/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_22/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_22/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.8it/s 13.9s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.445       0.31      0.297      0.122      0.416      0.276      0.246     0.0834\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_22\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_22.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 33.2Â±5.4 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 570.3it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.5s0.4ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.445      0.309      0.297      0.121      0.417      0.273      0.245     0.0834\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val87\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2449\n","      Mask mAP@0.5:0.95: 0.0834\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2449\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 23 complete!\n","\n","======================================================================\n","EPOCH 24/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 22 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 112 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 112\n","   Total: 793\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 793 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_22.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_23, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_23, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 842.7Â±123.0 MB/s, size: 29.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 793 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 793/793 1.1Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 29.0Â±8.7 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 562.5it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_23/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_23\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.609      3.088      1.954      1.718          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 199/199 8.3it/s 24.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.7s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.42      0.336      0.318      0.136      0.407      0.294      0.256     0.0872\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_23/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_23/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_23/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.422      0.334      0.318      0.136      0.404      0.295      0.255     0.0871\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_23\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_23.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 36.2Â±7.6 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 603.9it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.2s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.422      0.335      0.318      0.136      0.403      0.294      0.255      0.087\n","Speed: 1.1ms preprocess, 14.9ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val88\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2553\n","      Mask mAP@0.5:0.95: 0.0870\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2553\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 24 complete!\n","\n","======================================================================\n","EPOCH 25/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 23 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 29 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 29\n","   Total: 710\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 710 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_23.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_24, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_24, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 902.9Â±144.9 MB/s, size: 34.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 710 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 710/710 1.2Kit/s 0.6s<0.1s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.2Â±8.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 710.6it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_24/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_24\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.621      3.098       1.98      1.725         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 178/178 8.3it/s 21.5s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.396      0.303       0.27      0.114      0.347      0.266      0.219     0.0748\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_24/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_24/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_24/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.394      0.303       0.27      0.114      0.345      0.266      0.219     0.0747\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_24\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_24.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.6Â±10.9 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 578.9it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.39      0.306       0.27      0.114      0.343      0.267      0.219     0.0744\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val89\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2192\n","      Mask mAP@0.5:0.95: 0.0744\n","\n","   Current best: 0.2553 (epoch 24)\n","\n","âœ… Epoch 25 complete!\n","\n","======================================================================\n","EPOCH 26/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 24 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 38 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 38\n","   Total: 719\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 719 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_24.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_25, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_25, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 998.1Â±339.3 MB/s, size: 36.5 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 719 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.2Â±7.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 707.4it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_25/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_25\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.95G      1.595      3.057      1.971      1.729         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 180/180 8.4it/s 21.5s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.6it/s 16.0s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.388      0.333      0.293      0.128      0.377      0.285      0.244     0.0828\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_25/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_25/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_25/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.3it/s 13.1s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.388      0.333      0.293      0.128      0.375      0.286      0.244     0.0827\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_25\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_25.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 29.2Â±9.8 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 548.1it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.387      0.333      0.293      0.128      0.379      0.287      0.245     0.0827\n","Speed: 1.0ms preprocess, 14.6ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val90\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2447\n","      Mask mAP@0.5:0.95: 0.0827\n","\n","   Current best: 0.2553 (epoch 24)\n","\n","âœ… Epoch 26 complete!\n","\n","======================================================================\n","EPOCH 27/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 25 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 55 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 55\n","   Total: 736\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 736 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_25.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_26, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_26, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1069.7Â±353.2 MB/s, size: 41.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 736 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 736/736 1.2Kit/s 0.6s<0.0s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.0Â±8.8 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 718.0it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_26/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_26\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.593       3.04      1.912      1.693         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 184/184 8.3it/s 22.1s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.3s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.434      0.337      0.322      0.137      0.407      0.299      0.268     0.0933\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_26/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_26/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_26/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.3it/s 13.2s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.433      0.337      0.322      0.137      0.406      0.298      0.268     0.0933\n","Speed: 0.3ms preprocess, 5.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_26\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_26.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.9Â±8.7 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 587.7it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.432      0.337      0.322      0.137      0.407      0.299      0.268     0.0934\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val91\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2684\n","      Mask mAP@0.5:0.95: 0.0934\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2684\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 27 complete!\n","\n","======================================================================\n","EPOCH 28/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 26 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 47 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 47\n","   Total: 728\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 728 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_26.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_27, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_27, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1021.0Â±200.0 MB/s, size: 38.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 728 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 728/728 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.0Â±8.0 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 654.7it/s 1.5s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_27/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_27\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.99G      1.596      3.055      1.899      1.682         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 8.3it/s 22.0s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.5s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.413      0.323      0.302      0.129      0.373      0.291      0.251     0.0857\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_27/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_27/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_27/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.413      0.323      0.302      0.129      0.373      0.291      0.251     0.0857\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_27\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_27.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.8Â±7.6 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 546.4it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.415      0.324      0.302      0.129      0.374      0.292      0.252     0.0855\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val92\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2515\n","      Mask mAP@0.5:0.95: 0.0855\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 28 complete!\n","\n","======================================================================\n","EPOCH 29/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 27 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 83 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 83\n","   Total: 764\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 764 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_27.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_28, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_28, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 961.2Â±295.6 MB/s, size: 33.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 764 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 764/764 1.1Kit/s 0.7s<0.1s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.5Â±8.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 653.8it/s 1.5s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_28/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_28\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.581      3.071       1.88      1.696         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 191/191 8.3it/s 22.9s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.386      0.319      0.282      0.123       0.36      0.289      0.239     0.0829\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_28/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_28/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_28/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.3s<0.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.386      0.319      0.282      0.124      0.362      0.288      0.239      0.083\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_28\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_28.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.5Â±7.1 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 561.8it/s 1.7s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.386      0.319      0.282      0.123      0.363      0.288       0.24     0.0828\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val93\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2395\n","      Mask mAP@0.5:0.95: 0.0828\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 29 complete!\n","\n","======================================================================\n","EPOCH 30/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 28 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 105 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 105\n","   Total: 786\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 786 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_28.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_29, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_29, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 830.8Â±146.9 MB/s, size: 28.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 786 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 786/786 1.1Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.6Â±6.8 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 707.4it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_29/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_29\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.544      3.002      1.865      1.676         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 197/197 8.4it/s 23.5s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.2s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.438       0.32      0.308      0.125      0.395      0.291      0.258     0.0863\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_29/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_29/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_29/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.2s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.436      0.323      0.309      0.124      0.392      0.291      0.257     0.0862\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_29\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_29.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 30.0Â±7.9 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 571.5it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.5s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.435      0.322      0.308      0.124      0.393      0.288      0.257     0.0863\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val94\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2570\n","      Mask mAP@0.5:0.95: 0.0863\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 30 complete!\n","\n","======================================================================\n","EPOCH 31/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 29 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 92 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 92\n","   Total: 773\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 773 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_29.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_30, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_30, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1062.0Â±333.2 MB/s, size: 39.4 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 773 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 773/773 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.4Â±9.3 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 683.2it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_30/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_30\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.89G      1.614      3.048      1.834      1.716          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 194/194 8.4it/s 23.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.6s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.397      0.321       0.29      0.128       0.35      0.266      0.225     0.0788\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_30/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_30/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_30/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.6s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.395      0.324       0.29      0.128      0.351      0.266      0.225     0.0788\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_30\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_30.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.6Â±6.7 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 540.5it/s 1.8s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.2s0.4ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.391      0.325      0.289      0.128      0.351      0.266      0.225     0.0789\n","Speed: 1.1ms preprocess, 14.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val95\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2251\n","      Mask mAP@0.5:0.95: 0.0789\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 31 complete!\n","\n","======================================================================\n","EPOCH 32/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 30 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 30 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 30\n","   Total: 711\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 711 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_30.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_31, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_31, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 941.3Â±276.2 MB/s, size: 32.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 711 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 711/711 1.2Kit/s 0.6s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 20.7Â±12.4 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 647.4it/s 1.5s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_31/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_31\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.94G      1.559      3.055       1.83      1.665         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 178/178 8.3it/s 21.4s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.5s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.371       0.32      0.257      0.113      0.326      0.272      0.196     0.0677\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_31/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_31/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_31/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.5s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.37       0.32      0.258      0.113      0.325      0.273      0.197      0.068\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_31\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_31.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.7Â±9.3 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 539.2it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.368      0.324      0.257      0.113      0.325      0.272      0.196     0.0676\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val96\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.1959\n","      Mask mAP@0.5:0.95: 0.0676\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 32 complete!\n","\n","======================================================================\n","EPOCH 33/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 31 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 84 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 84\n","   Total: 765\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 765 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_31.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 837.2Â±203.0 MB/s, size: 27.4 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 765 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 765/765 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.2Â±10.2 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 703.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_32/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_32\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.575      3.011      1.881      1.669          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 192/192 8.4it/s 22.8s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.397      0.336      0.293      0.129      0.393        0.3      0.254     0.0897\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_32/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_32/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_32/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.3s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.397      0.337      0.294      0.129      0.391      0.301      0.254     0.0897\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_32\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_32.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.3Â±5.1 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 569.0it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.8s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.399      0.337      0.294      0.129      0.391      0.301      0.254     0.0895\n","Speed: 1.0ms preprocess, 14.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val97\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2545\n","      Mask mAP@0.5:0.95: 0.0895\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 33 complete!\n","\n","======================================================================\n","EPOCH 34/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 32 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 57.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 63 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 63\n","   Total: 744\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 744 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_32.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_33, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_33, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1019.2Â±310.2 MB/s, size: 40.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 744 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 744/744 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.2Â±9.0 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 696.3it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_33/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_33\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.543      2.983      1.852      1.659         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 186/186 8.4it/s 22.3s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.5s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.414      0.328      0.298      0.129      0.403      0.293      0.255     0.0937\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_33/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_33/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_33/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.5s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.414      0.328      0.297      0.129      0.401      0.295      0.255     0.0935\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_33\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_33.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.9Â±6.7 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 571.1it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.9s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.415      0.328      0.298      0.129      0.402      0.292      0.255     0.0935\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val98\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2551\n","      Mask mAP@0.5:0.95: 0.0935\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 34 complete!\n","\n","======================================================================\n","EPOCH 35/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 33 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 107 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 107\n","   Total: 788\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 788 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_33.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_34, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_34, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 852.4Â±275.4 MB/s, size: 29.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 788 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 788/788 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.0Â±6.3 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 688.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_34/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_34\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.96G      1.551      2.954      1.838       1.67         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 197/197 8.4it/s 23.6s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.378      0.331      0.283      0.126      0.383      0.277       0.23     0.0812\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_34/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_34/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_34/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.378      0.331      0.283      0.126      0.383      0.278       0.23     0.0814\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_34\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_34.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.7Â±3.0 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 536.4it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.379      0.331      0.283      0.126      0.383      0.279       0.23     0.0811\n","Speed: 1.0ms preprocess, 14.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val99\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2301\n","      Mask mAP@0.5:0.95: 0.0811\n","\n","   Current best: 0.2684 (epoch 27)\n","\n","âœ… Epoch 35 complete!\n","\n","======================================================================\n","EPOCH 36/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 34 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 133 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 133\n","   Total: 814\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 814 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_34.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_35, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_35, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 940.2Â±279.0 MB/s, size: 30.8 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 814 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 814/814 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.8Â±7.1 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 677.5it/s 1.4s<0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_35/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_35\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.547       2.89      1.827      1.649          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 204/204 8.4it/s 24.3s<0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.458      0.322      0.319      0.144      0.456      0.303       0.29      0.106\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_35/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_35/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_35/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.2s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.457      0.322      0.319      0.144      0.455      0.303       0.29      0.106\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_35\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_35.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.0Â±8.7 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 573.4it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.459       0.32      0.318      0.144      0.451      0.304       0.29      0.106\n","Speed: 1.1ms preprocess, 14.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val100\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2901\n","      Mask mAP@0.5:0.95: 0.1059\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2901\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 36 complete!\n","\n","======================================================================\n","EPOCH 37/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 35 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 108 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 108\n","   Total: 789\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 789 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_35.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_36, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_36, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 976.9Â±275.0 MB/s, size: 34.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 789 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 789/789 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.0Â±6.2 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 696.2it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_36/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_36\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.528      2.954       1.77      1.665          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 8.3it/s 23.8s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.424      0.301      0.279      0.124      0.399      0.276      0.248     0.0928\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_36/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_36/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_36/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.421      0.303      0.279      0.123      0.401      0.274      0.248     0.0928\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_36\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_36.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 35.0Â±5.5 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 580.8it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.421      0.302      0.279      0.123      0.396      0.274      0.245     0.0914\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val101\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2453\n","      Mask mAP@0.5:0.95: 0.0914\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 37 complete!\n","\n","======================================================================\n","EPOCH 38/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 36 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 104 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 104\n","   Total: 785\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 785 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_36.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_37, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_37, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 952.4Â±315.2 MB/s, size: 34.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 785 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 785/785 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 25.0Â±7.4 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 706.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_37/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_37\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1       1.9G      1.532      2.894      1.807      1.634          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 197/197 8.3it/s 23.7s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.7it/s 15.8s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.452      0.315      0.294       0.13      0.406      0.278      0.248       0.09\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_37/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_37/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_37/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.6it/s 12.7s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.452      0.316      0.295       0.13      0.407      0.278      0.248     0.0904\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_37\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_37.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.8Â±5.4 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 518.2it/s 1.9s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.449      0.318      0.294       0.13      0.408      0.277      0.247     0.0895\n","Speed: 1.0ms preprocess, 14.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val102\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2470\n","      Mask mAP@0.5:0.95: 0.0895\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 38 complete!\n","\n","======================================================================\n","EPOCH 39/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 37 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 53 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 53\n","   Total: 734\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 734 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_37.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_38, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_38, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 946.2Â±258.8 MB/s, size: 32.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 734 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 734/734 1.2Kit/s 0.6s<0.0s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.8Â±6.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 718.6it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_38/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_38\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.94G      1.559      2.992      1.799      1.666         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 184/184 8.4it/s 22.0s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.3it/s 16.7s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.381      0.349      0.292      0.131       0.37       0.31      0.245     0.0867\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_38/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_38/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_38/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 8.9it/s 13.7s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.383       0.35      0.292      0.131      0.371      0.308      0.245     0.0866\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_38\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_38.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.0Â±4.6 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 554.1it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.3s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.382      0.349      0.292      0.131      0.371      0.309      0.245     0.0868\n","Speed: 1.1ms preprocess, 14.9ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val103\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2446\n","      Mask mAP@0.5:0.95: 0.0868\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 39 complete!\n","\n","======================================================================\n","EPOCH 40/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 38 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 107 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 107\n","   Total: 788\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 788 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_38.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_39, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_39, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 833.6Â±291.7 MB/s, size: 32.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 788 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 788/788 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 22.3Â±6.1 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 702.4it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_39/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_39\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.524      2.907      1.742      1.631         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 197/197 8.4it/s 23.5s0.1ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.5s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.439      0.368      0.327      0.151      0.438      0.296       0.27     0.0972\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_39/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_39/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_39/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.437       0.37      0.329      0.151      0.434      0.299      0.272     0.0973\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_39\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_39.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 30.9Â±7.7 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 550.3it/s 1.8s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.8s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.437      0.368      0.326      0.151      0.437      0.296       0.27     0.0967\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val104\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2698\n","      Mask mAP@0.5:0.95: 0.0967\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 40 complete!\n","\n","======================================================================\n","EPOCH 41/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 39 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 82 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 82\n","   Total: 763\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 763 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_39.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_40, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_40, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 890.1Â±189.0 MB/s, size: 33.0 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 763 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 763/763 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 22.4Â±7.2 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 720.1it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_40/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_40\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.94G      1.506      2.867      1.729      1.605         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 191/191 8.3it/s 22.9s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.3s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.402      0.369      0.316      0.148      0.385      0.323       0.27        0.1\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_40/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_40/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_40/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.5s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.402       0.37      0.317      0.148      0.382      0.323       0.27        0.1\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_40\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_40.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.5Â±4.8 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 591.7it/s 1.6s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.402      0.369      0.317      0.148      0.381      0.323       0.27        0.1\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val105\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2702\n","      Mask mAP@0.5:0.95: 0.1002\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 41 complete!\n","\n","======================================================================\n","EPOCH 42/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 40 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 121 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 121\n","   Total: 802\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 802 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_40.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_41, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_41, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1030.8Â±301.8 MB/s, size: 35.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 802 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 802/802 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.8Â±8.2 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 689.5it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_41/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_41\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.515      2.906      1.754      1.631         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 201/201 8.3it/s 24.1s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.414      0.347       0.31      0.146       0.41       0.32      0.267      0.101\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_41/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_41/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_41/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.3s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.414      0.348       0.31      0.146      0.408       0.32      0.265      0.101\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_41\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_41.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 35.1Â±7.0 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 569.4it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.8s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.414      0.349      0.311      0.146      0.409      0.321      0.265      0.101\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val106\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2647\n","      Mask mAP@0.5:0.95: 0.1011\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 42 complete!\n","\n","======================================================================\n","EPOCH 43/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 41 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 123 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 123\n","   Total: 804\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 804 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_41.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 868.5Â±190.9 MB/s, size: 30.4 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 804 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 804/804 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 26.3Â±8.3 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 718.2it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_42/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_42\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.94G      1.493      2.853      1.742      1.602         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 201/201 8.3it/s 24.1s<0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.2s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.551      0.294      0.334      0.149      0.524      0.264      0.278      0.101\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_42/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_42/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_42/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.3it/s 13.1s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.546      0.294      0.334      0.149      0.524      0.265      0.279      0.101\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_42\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_42.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 33.7Â±4.8 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 574.2it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.544      0.294      0.334      0.149       0.52      0.264      0.278      0.101\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val107\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2779\n","      Mask mAP@0.5:0.95: 0.1008\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 43 complete!\n","\n","======================================================================\n","EPOCH 44/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 42 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 131 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 131\n","   Total: 812\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 812 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_42.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_43, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_43, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 918.6Â±249.9 MB/s, size: 31.8 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 812 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 812/812 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.4Â±7.5 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 705.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_43/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_43\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.97G      1.503       2.91      1.724      1.644         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 203/203 8.3it/s 24.4s<0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.5it/s 16.2s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.437      0.346      0.311      0.135      0.382      0.309      0.249     0.0827\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_43/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_43/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_43/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.2s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.445      0.343      0.311      0.135      0.382      0.309      0.248     0.0825\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_43\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_43.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 32.6Â±2.7 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 581.9it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.4s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.436      0.346      0.311      0.135       0.38      0.308      0.249     0.0828\n","Speed: 1.0ms preprocess, 14.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val108\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2486\n","      Mask mAP@0.5:0.95: 0.0828\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 44 complete!\n","\n","======================================================================\n","EPOCH 45/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 43 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 54.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 211 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 211\n","   Total: 892\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 892 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_43.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_44, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_44, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 922.7Â±294.3 MB/s, size: 31.1 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 892 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 892/892 1.1Kit/s 0.8s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 21.9Â±6.7 MB/s, size: 28.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 700.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_44/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_44\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.545      3.033      1.755      1.672          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 223/223 8.4it/s 26.6s<0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.7it/s 15.9s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.451      0.328      0.314      0.137        0.4      0.288      0.254       0.09\n","\n","1 epochs completed in 0.013 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_44/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_44/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_44/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.3it/s 13.0s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.45      0.329      0.314      0.137      0.402      0.287      0.254     0.0901\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_44\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_44.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 32.3Â±5.1 MB/s, size: 38.6 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 596.1it/s 1.6s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.4s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.452       0.33      0.314      0.137      0.402      0.288      0.255     0.0899\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val109\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2545\n","      Mask mAP@0.5:0.95: 0.0899\n","\n","   Current best: 0.2901 (epoch 36)\n","\n","âœ… Epoch 45 complete!\n","\n","======================================================================\n","EPOCH 46/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 44 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 54 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 54\n","   Total: 735\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 735 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_44.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_45, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_45, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1008.1Â±183.1 MB/s, size: 38.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 735 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 735/735 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.6Â±5.9 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 714.7it/s 1.4s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_45/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_45\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.492      2.876      1.677      1.609          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 184/184 8.3it/s 22.1s0.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.5s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.465      0.336      0.345      0.158      0.446      0.308      0.296      0.104\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_45/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_45/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_45/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.0it/s 13.5s0.2ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.467      0.335      0.345      0.158      0.446      0.308      0.296      0.104\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_45\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_45.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 18.7Â±6.4 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 418.7it/s 2.3s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.7s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.469      0.335      0.346      0.158      0.449      0.306      0.295      0.103\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val110\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2953\n","      Mask mAP@0.5:0.95: 0.1034\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2953\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 46 complete!\n","\n","======================================================================\n","EPOCH 47/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 45 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 55.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 128 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 128\n","   Total: 809\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 809 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_45.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_46, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_46, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 871.6Â±195.2 MB/s, size: 29.0 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 809 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 809/809 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 19.1Â±7.4 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 508.9it/s 1.9s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_46/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_46\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.92G      1.484      2.831      1.683      1.614          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 203/203 8.4it/s 24.2s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.6it/s 16.1s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.442      0.339      0.315      0.144       0.46       0.31      0.294      0.106\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_46/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_46/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_46/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.4it/s 13.0s<0.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.441      0.338      0.315      0.144       0.46      0.309      0.293      0.105\n","Speed: 0.3ms preprocess, 5.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_46\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_46.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 32.1Â±3.0 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 560.6it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.4s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.442      0.339      0.316      0.144      0.461       0.31      0.295      0.106\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val111\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2953\n","      Mask mAP@0.5:0.95: 0.1060\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.2953\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 47 complete!\n","\n","======================================================================\n","EPOCH 48/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 46 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 85 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 85\n","   Total: 766\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 766 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_46.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_47, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_47, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 946.6Â±243.5 MB/s, size: 33.4 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 766 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 766/766 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.2Â±9.3 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 708.5it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_47/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_47\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.463      2.896      1.695       1.59          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 192/192 8.3it/s 23.0s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.378      0.355      0.296      0.131      0.362      0.324      0.253     0.0867\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_47/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_47/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_47/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.2it/s 13.3s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.379      0.357      0.296      0.131      0.367      0.325      0.254     0.0865\n","Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_47\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_47.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.5Â±9.4 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 587.9it/s 1.7s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.6s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.377      0.356      0.296      0.131      0.362      0.324      0.253     0.0868\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val112\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2525\n","      Mask mAP@0.5:0.95: 0.0868\n","\n","   Current best: 0.2953 (epoch 47)\n","\n","âœ… Epoch 48 complete!\n","\n","======================================================================\n","EPOCH 49/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 47 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 100 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 100\n","   Total: 781\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 781 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_47.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_48, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_48, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 873.0Â±276.9 MB/s, size: 28.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 781 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 781/781 1.2Kit/s 0.7s0.1ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 24.2Â±7.3 MB/s, size: 32.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 704.7it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_48/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_48\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.91G      1.493      2.776      1.695      1.611          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 196/196 8.3it/s 23.6s0.2ss\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.6it/s 16.1s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.46      0.348      0.336      0.156      0.472      0.302      0.292       0.11\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_48/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_48/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_48/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.3it/s 13.1s<0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.464      0.347      0.336      0.156      0.469      0.303      0.292       0.11\n","Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_48\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_48.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 30.5Â±6.4 MB/s, size: 39.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 568.9it/s 1.7s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.4s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.457      0.348      0.335      0.155      0.472      0.303      0.293       0.11\n","Speed: 1.1ms preprocess, 14.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val113\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.2926\n","      Mask mAP@0.5:0.95: 0.1102\n","\n","   Current best: 0.2953 (epoch 47)\n","\n","âœ… Epoch 49 complete!\n","\n","======================================================================\n","EPOCH 50/50\n","======================================================================\n","\n","ðŸ“¦ Loading models...\n","   Using epoch 48 weights\n","âœ… Models loaded\n","\n","ðŸ·ï¸  Generating pseudo-labels with teacher model...\n"]},{"name":"stderr","output_type":"stream","text":["Teacher (confâ‰¥0.6): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409/409 [00:07<00:00, 56.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","   âœ… Generated 59 pseudo-labeled images\n","\n","ðŸ“¦ Merging datasets...\n","   Labeled: 681\n","   Pseudo-labeled: 59\n","   Total: 740\n","âœ… Datasets merged\n","\n","ðŸŽ“ Training student model...\n","   Training data: 740 images\n","   Epochs: 1 (incremental)\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/mt_merged.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/mt_epoch_48.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mt_epoch_49, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/mt_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/mt_runs/mt_epoch_49, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n","YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients\n","\n","Transferred 417/417 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 944.1Â±249.4 MB/s, size: 35.1 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/mt_merged/labels... 740 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 740/740 1.2Kit/s 0.6s0.0ss\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/mt_merged/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 28.1Â±7.2 MB/s, size: 34.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 700.1it/s 1.4s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","Plotting labels to /kaggle/working/mt_runs/mt_epoch_49/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/kaggle/working/mt_runs/mt_epoch_49\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/1      1.93G      1.469      2.815      1.633      1.576         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 185/185 8.3it/s 22.2s0.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 7.4it/s 16.4s0.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.463      0.378      0.364      0.171      0.453      0.343      0.315       0.12\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_49/weights/last.pt, 23.8MB\n","Optimizer stripped from /kaggle/working/mt_runs/mt_epoch_49/weights/best.pt, 23.8MB\n","\n","Validating /kaggle/working/mt_runs/mt_epoch_49/weights/best.pt...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 122/122 9.1it/s 13.4s0.1ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888       0.46       0.38      0.364      0.171      0.453      0.343      0.315       0.12\n","Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/mt_runs/mt_epoch_49\u001b[0m\n","âœ… Checkpoint saved: /kaggle/working/mt_epoch_49.pt\n","\n","ðŸ“Š Validating student model...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 27.7Â±4.0 MB/s, size: 35.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid/labels... 974 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 974/974 606.9it/s 1.6s0.1s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/valid is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.5s0.3ss\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        974       1888      0.464      0.379      0.363      0.171      0.452      0.342      0.316      0.119\n","Speed: 1.1ms preprocess, 14.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val114\u001b[0m\n","\n","   ðŸ“ˆ Metrics:\n","      Mask mAP@0.5:      0.3156\n","      Mask mAP@0.5:0.95: 0.1192\n","\n","   ðŸŽ¯ NEW BEST MODEL!\n","      Best mAP@0.5: 0.3156\n","      Saved to: /kaggle/working/mt_best.pt\n","\n","âœ… Epoch 50 complete!\n","\n","======================================================================\n","MEAN TEACHER TRAINING COMPLETE\n","======================================================================\n","\n","ðŸ† Best Results:\n","   Best mAP@0.5: 0.3156\n","   Best epoch: 50/50\n","   Best model: /kaggle/working/mt_best.pt\n"]}],"execution_count":15},{"cell_type":"code","source":"# ============================================================\n# CELL 9: FINAL TEST EVALUATION\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL TEST EVALUATION\")\nprint(\"=\"*70)\n\nprint(f\"\\nðŸ“Š Evaluating on test set...\")\nmt_final_model = YOLO(best_model_path)\nmt_test_metrics = mt_final_model.val(split=\"test\", verbose=False)\n\nprint(f\"\\n{'='*70}\")\nprint(f\"MEAN TEACHER - FINAL TEST RESULTS\")\nprint(f\"{'='*70}\")\nprint(f\"\\nðŸ“Š Segmentation Metrics:\")\nprint(f\"   Mask mAP@0.5:      {mt_test_metrics.seg.map50:.4f}\")\nprint(f\"   Mask mAP@0.5:0.95: {mt_test_metrics.seg.map:.4f}\")\nprint(f\"\\nðŸ“Š Detection Metrics:\")\nprint(f\"   Box mAP@0.5:       {mt_test_metrics.box.map50:.4f}\")\nprint(f\"   Box mAP@0.5:0.95:  {mt_test_metrics.box.map:.4f}\")\nprint(f\"{'='*70}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T20:18:17.286561Z","iopub.status.busy":"2025-12-02T20:18:17.286141Z","iopub.status.idle":"2025-12-02T20:18:34.494202Z","shell.execute_reply":"2025-12-02T20:18:34.493358Z","shell.execute_reply.started":"2025-12-02T20:18:17.286534Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","FINAL TEST EVALUATION\n","======================================================================\n","\n","ðŸ“Š Evaluating on test set...\n","Ultralytics 8.3.234 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.2Â±1.1 ms, read: 32.7Â±7.2 MB/s, size: 34.6 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/test/labels... 487 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 487/487 390.8it/s 1.2s0.0s\n","WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/car-damage-detection-3/Car-Damage detection.v1i.yolov8/test is not writable, cache not saved.\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.6it/s 11.9s0.3s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n","/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n","  xa[xa < 0] = -1\n"]},{"name":"stdout","output_type":"stream","text":["                   all        487        958      0.463      0.392      0.384      0.182      0.487      0.323       0.32      0.124\n","Speed: 1.4ms preprocess, 14.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1m/kaggle/working/runs/segment/val115\u001b[0m\n","\n","======================================================================\n","MEAN TEACHER - FINAL TEST RESULTS\n","======================================================================\n","\n","ðŸ“Š Segmentation Metrics:\n","   Mask mAP@0.5:      0.3202\n","   Mask mAP@0.5:0.95: 0.1239\n","\n","ðŸ“Š Detection Metrics:\n","   Box mAP@0.5:       0.3839\n","   Box mAP@0.5:0.95:  0.1821\n","======================================================================\n"]}],"execution_count":16},{"cell_type":"code","source":"# ============================================================\n# CELL 10: SAVE BEST MODEL FOR DOWNLOAD\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"SAVING MODELS\")\nprint(\"=\"*70)\n\n# Copy best model to root for easy download\nshutil.copy(best_model_path, \"/kaggle/working/meanteacher_best.pt\")\n\nprint(f\"\\nâœ… Models saved:\")\nprint(f\"   Best model: /kaggle/working/meanteacher_best.pt\")\nprint(f\"   ({os.path.getsize('/kaggle/working/meanteacher_best.pt')/1024/1024:.1f} MB)\")\n\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… MEAN TEACHER COMPLETE!\")\nprint(\"=\"*70)\nprint(f\"\\nðŸ“¥ Download 'meanteacher_best.pt' from Output panel\")\nprint(f\"   Size: {os.path.getsize('/kaggle/working/meanteacher_best.pt')/1024/1024:.1f} MB\")\nprint(f\"   Test mAP@0.5: {mt_test_metrics.seg.map50:.4f}\")\nprint(\"\\n\" + \"=\"*70)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-02T20:23:19.443645Z","iopub.status.busy":"2025-12-02T20:23:19.442789Z","iopub.status.idle":"2025-12-02T20:23:19.485050Z","shell.execute_reply":"2025-12-02T20:23:19.484400Z","shell.execute_reply.started":"2025-12-02T20:23:19.443611Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","SAVING MODELS\n","======================================================================\n","\n","âœ… Models saved:\n","   Best model: /kaggle/working/meanteacher_best.pt\n","   (22.6 MB)\n","\n","======================================================================\n","âœ… MEAN TEACHER COMPLETE!\n","======================================================================\n","\n","ðŸ“¥ Download 'meanteacher_best.pt' from Output panel\n","   Size: 22.6 MB\n","   Test mAP@0.5: 0.3202\n","\n","======================================================================\n"]}],"execution_count":17}]}